% Aqui só fui jogando os artigos, recomendo tirar o abstract em outros trabalhos porque ocupa muito espaço no arquivo


@article{Cho:2020,
    author = {Cho, Se Jin and Sunwoo, Leonard and Baik, Sung Hyun and Bae, Yun Jung and Choi, Byung Se and Kim, Jae Hyoung},
    title = "{Brain metastasis detection using machine learning: a systematic review and meta-analysis}",
    journal = {Neuro-Oncology},
    volume = {23},
    number = {2},
    pages = {214-225},
    year = {2020},
    month = {10},
    abstract = "{Accurate detection of brain metastasis (BM) is important for cancer patients. We aimed to systematically review the performance and quality of machine-learning-based BM detection on MRI in the relevant literature.A systematic literature search was performed for relevant studies reported before April 27, 2020. We assessed the quality of the studies using modified tailored questionnaires of the Quality Assessment of Diagnostic Accuracy Studies 2 (QUADAS-2) criteria and the Checklist for Artificial Intelligence in Medical Imaging (CLAIM). Pooled detectability was calculated using an inverse-variance weighting model.A total of 12 studies were included, which showed a clear transition from classical machine learning (cML) to deep learning (DL) after 2018. The studies on DL used a larger sample size than those on cML. The cML and DL groups also differed in the composition of the dataset, and technical details such as data augmentation. The pooled proportions of detectability of BM were 88.7\% (95\% CI, 84–93\%) and 90.1\% (95\% CI, 84–95\%) in the cML and DL groups, respectively. The false-positive rate per person was lower in the DL group than the cML group (10 vs 135, P \\&lt; 0.001). In the patient selection domain of QUADAS-2, three studies (25\%) were designated as high risk due to non-consecutive enrollment and arbitrary exclusion of nodules.A comparable detectability of BM with a low false-positive rate per person was found in the DL group compared with the cML group. Improvements are required in terms of quality and study design.}",
    issn = {1522-8517},
    doi = {10.1093/neuonc/noaa232},
    url = {https://doi.org/10.1093/neuonc/noaa232},
    eprint = {https://academic.oup.com/neuro-oncology/article-pdf/23/2/214/36357014/noaa232.pdf},
}


@article{Grovik:2020,
author = {Gr{\o}vik, Endre and Yi, Darvin and Iv, Michael and Tong, Elizabeth and Rubin, Daniel and Zaharchuk, Greg},
title = {Deep learning enables automatic detection and segmentation of brain metastases on multisequence MRI},
journal = {Journal of Magnetic Resonance Imaging},
volume = {51},
number = {1},
pages = {175-182},
keywords = {deep learning, segmentation, brain metastases, multisequence},
doi = {https://doi.org/10.1002/jmri.26766},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.26766},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.26766},
abstract = {Background Detecting and segmenting brain metastases is a tedious and time-consuming task for many radiologists, particularly with the growing use of multisequence 3D imaging. Purpose To demonstrate automated detection and segmentation of brain metastases on multisequence MRI using a deep-learning approach based on a fully convolution neural network (CNN). Study Type Retrospective. Population In all, 156 patients with brain metastases from several primary cancers were included. Field Strength 1.5T and 3T. [Correction added on May 24, 2019, after first online publication: In the preceding sentence, the first field strength listed was corrected.] Sequence Pretherapy MR images included pre- and postgadolinium T1-weighted 3D fast spin echo (CUBE), postgadolinium T1-weighted 3D axial IR-prepped FSPGR (BRAVO), and 3D CUBE fluid attenuated inversion recovery (FLAIR). Assessment The ground truth was established by manual delineation by two experienced neuroradiologists. CNN training/development was performed using 100 and 5 patients, respectively, with a 2.5D network based on a GoogLeNet architecture. The results were evaluated in 51 patients, equally separated into those with few (1–3), multiple (4–10), and many (>10) lesions. Statistical Tests Network performance was evaluated using precision, recall, Dice/F1 score, and receiver operating characteristic (ROC) curve statistics. For an optimal probability threshold, detection and segmentation performance was assessed on a per-metastasis basis. The Wilcoxon rank sum test was used to test the differences between patient subgroups. Results The area under the ROC curve (AUC), averaged across all patients, was 0.98 ± 0.04. The AUC in the subgroups was 0.99 ± 0.01, 0.97 ± 0.05, and 0.97 ± 0.03 for patients having 1–3, 4–10, and >10 metastases, respectively. Using an average optimal probability threshold determined by the development set, precision, recall, and Dice score were 0.79 ± 0.20, 0.53 ± 0.22, and 0.79 ± 0.12, respectively. At the same probability threshold, the network showed an average false-positive rate of 8.3/patient (no lesion-size limit) and 3.4/patient (10 mm3 lesion size limit). Data Conclusion A deep-learning approach using multisequence MRI can automatically detect and segment brain metastases with high accuracy. Level of Evidence: 3 Technical Efficacy Stage: 2 J. Magn. Reson. Imaging 2020;51:175–182.},
year = {2020}
}

@ARTICLE{Ottesen:2023,
AUTHOR={Ottesen, Jon André and Yi, Darvin and Tong, Elizabeth and Iv, Michael and Latysheva, Anna and Saxhaug, Cathrine and Jacobsen, Kari Dolven and Helland, Aslaug and Emblem, Kyrre Eeg and Rubin, Daniel L. and BjØrnerud, Atle and Zaharchuk, Greg and GrØvik, Endre},   
	 
TITLE={2.5D and 3D segmentation of brain metastases with deep learning on multinational MRI data},      
	
JOURNAL={Frontiers in Neuroinformatics},      
	
VOLUME={16},           
	
YEAR={2023},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fninf.2022.1056068},       
	
DOI={10.3389/fninf.2022.1056068},      
	
ISSN={1662-5196},   
   
ABSTRACT={IntroductionManagement of patients with brain metastases is often based on manual lesion detection and segmentation by an expert reader. This is a time- and labor-intensive process, and to that end, this work proposes an end-to-end deep learning segmentation network for a varying number of available MRI available sequences.MethodsWe adapt and evaluate a 2.5D and a 3D convolution neural network trained and tested on a retrospective multinational study from two independent centers, in addition, nnU-Net was adapted as a comparative benchmark. Segmentation and detection performance was evaluated by: (1) the dice similarity coefficient, (2) a per-metastases and the average detection sensitivity, and (3) the number of false positives. Results The 2.5D and 3D models achieved similar results, albeit the 2.5D model had better detection rate, whereas the 3D model had fewer false positive predictions, and nnU-Net had fewest false positives, but with the lowest detection rate. On MRI data from center 1, the 2.5D, 3D, and nnU-Net detected 79\%, 71\%, and 65\% of all metastases; had an average per patient sensitivity of 0.88, 0.84, and 0.76; and had on average 6.2, 3.2, and 1.7 false positive predictions per patient, respectively. For center 2, the 2.5D, 3D, and nnU-Net detected 88\%, 86\%, and 78\% of all metastases; had an average per patient sensitivity of 0.92, 0.91, and 0.85; and had on average 1.0, 0.4, and 0.1 false positive predictions per patient, respectively. Discussion/ConclusionOur results show that deep learning can yield highly accurate segmentations of brain metastases with few false positives in multinational data, but the accuracy degrades for metastases with an area smaller than 0.4 cm².}
}

@article{ElNaqa:2021,
author = {El Naqa, Issam and Boone, John M. and Benedict, Stanley H. and Goodsitt, Mitchell M. and Chan, Heang-Ping and Drukker, Karen and Hadjiiski, Lubomir and Ruan, Dan and Sahiner, Berkman},
title = {AI in medical physics: guidelines for publication},
journal = {Medical Physics},
volume = {48},
number = {9},
pages = {4711-4714},
doi = {https://doi.org/10.1002/mp.15170},
url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.15170},
eprint = {https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.15170},
abstract = {The Abstract is intended to provide a concise summary of the study and its scientific findings. For AI/ML applications in medical physics, a problem statement and rationale for utilizing these algorithms are necessary while highlighting the novelty of the approach. A brief numerical description of how the data are partitioned into subsets for training of the AI/ML algorithm, validation (including tuning of parameters), and independent testing of algorithm performance is required. This is to be followed by a summary of the results and statistical metrics that quantify the performance of the AI/ML algorithm.},
year = {2021}
}

@ARTICLE{Niranjan:2019,
  title    = "Guidelines for Multiple Brain Metastases Radiosurgery",
  author   = "Niranjan, Ajay and Monaco, Edward and Flickinger, John and
              Lunsford, L Dade",
  abstract = "Stereotactic radiosurgery (SRS) is an effective treatment for
              patients with multiple brain metastases. Three decades of
              increasingly powerful scientific studies have shown that SRS
              improves outcomes and reduces toxicity when it replaces
              whole-brain radiation therapy (WBRT). Expert opinion surveys of
              clinicians have reported that the total intracranial tumor volume
              rather than the number of brain metastases is related to
              outcomes. As a result, an increasing number of treating and
              referring physicians have replaced the reflex use of WBRT with
              SRS, unless the patient has miliary disease or carcinomatous
              meningitis. In the current era of immunotherapy and targeted
              therapies with potentially increased systemic disease survival,
              10 or more tumors are routinely treated with SRS alone at most
              academic medical centers. In a single SRS session we routinely
              treat patients with cumulative tumor volumes of 25 cm3 even if
              they have $\geq$10 metastases.",
  journal  = "Prog Neurol Surg",
  volume   =  34,
  pages    = "100--109",
  month    =  may,
  year     =  2019,
  address  = "Switzerland",
  language = "en"
}

@article {Achrol:2019,
	Title = {Brain metastases},
	Author = {Achrol, Achal Singh and Rennert, Robert C and Anders, Carey and Soffietti, Riccardo and Ahluwalia, Manmeet S and Nayak, Lakshmi and Peters, Solange and Arvold, Nils D and Harsh, Griffith R and Steeg, Patricia S and Chang, Steven D},
	DOI = {10.1038/s41572-018-0055-y},
	Number = {1},
	Volume = {5},
	Month = {January},
	Year = {2019},
	Journal = {Nature reviews. Disease primers},
	ISSN = {2056-676X},
	Pages = {5},
	Abstract = {An estimated 20\% of all patients with cancer will develop brain metastases, with the majority of brain metastases occurring in those with lung, breast and colorectal cancers, melanoma or renal cell carcinoma. Brain metastases are thought to occur via seeding of circulating tumour cells into the brain microvasculature; within this unique microenvironment, tumour growth is promoted and the penetration of systemic medical therapies is limited. Development of brain metastases remains a substantial contributor to overall cancer mortality in patients with advanced-stage cancer because prognosis remains poor despite multimodal treatments and advances in systemic therapies, which include a combination of surgery, radiotherapy, chemotherapy, immunotherapy and targeted therapies. Thus, interest abounds in understanding the mechanisms that drive brain metastases so that they can be targeted with preventive therapeutic strategies and in understanding the molecular characteristics of brain metastases relative to the primary tumour so that they can inform targeted therapy selection. Increased molecular understanding of the disease will also drive continued development of novel immunotherapies and targeted therapies that have higher bioavailability beyond the blood-tumour barrier and drive advances in radiotherapies and minimally invasive surgical techniques. As these discoveries and innovations move from the realm of basic science to preclinical and clinical applications, future outcomes for patients with brain metastases are almost certain to improve.},
	URL = {https://doi.org/10.1038/s41572-018-0055-y},
}

@book{Shaw:2005,
	Title = {Critérios de Adequação de Exames de Imagem e Radioterapia},
	Author = {Shaw, Edward G and Gaspar, Laurie E and Gibbs, Frederic A and Lewin, Alan A and Wharam Jr, Moody D and Larson, David and Bloomer, William D and Buckley, Judith A and Loeffler, Jay S and Malcolm, Arnold W and Mendenhall, William M and Schneider, Joseph F and Schupak, Karen D and Simpson, Joseph R and Gutin, Philip H and Rogers, Lisa and Leibel, Steven},
    Subtitle = {Metástases Cerebrais Múltiplas},
	Year = {2005},
	Publisher = {Colégio Brasileiro de Radiologia e Diagnóstico por Imagem},
    ISBN = {85-87950-06-1},
    url = {https://cbr.org.br/wp-content/uploads/2017/06/07_03.pdf}
}

@article{Mongan:2020,
author = {Mongan, John and Moy, Linda and Kahn, Charles                             E.},
title = {Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A                     Guide for Authors and Reviewers},
journal = {Radiology: Artificial Intelligence},
volume = {2},
number = {2},
pages = {e200029},
year = {2020},
doi = {10.1148/ryai.2020200029},
    note ={PMID: 33937821},

URL = {https://doi.org/10.1148/ryai.2020200029},
eprint = {https://doi.org/10.1148/ryai.2020200029}
}

@Article{Voulodimos:2018,
author={Voulodimos, Athanasios
and Doulamis, Nikolaos
and Doulamis, Anastasios
and Protopapadakis, Eftychios},
title={Deep Learning for Computer Vision: A Brief Review},
journal={Computational Intelligence and Neuroscience},
year={2018},
month={Feb},
day={01},
publisher={Hindawi},
volume={2018},
pages={7068349},
abstract={Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.},
issn={1687-5265},
doi={10.1155/2018/7068349},
url={https://doi.org/10.1155/2018/7068349}
}

@InProceedings{Ronneberger:2015,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@Conference{Mackie:2023,
    author = {Mackie, Thomas Rockwell and Gregoire, Vincent},
    title = {Assessment and Management of Uncertainties: Overview and Examples in Different Diseases Sites},
    month = {Aug},
    year = {2011},
    organization = {AAPM Summer School},
    url = {https://www.aapm.org/meetings/2011SS/documents/MackieUncertainty.pdf}
    
}

@Book{Lee:2013,
author={Lee, Nancy Y.},
title={Target volume delineation and field setup A practical guide for conformal and intensity-modulated radiation therapy},
year={2013},
publisher={Springer},
address={Germany},
abstract={Practical handbook on selection and delineation of tumor volumes and fields for conformal radiation therapy, including IMRT Helpful format facilitating use on a step-by-step basis in daily practice Designed to ensure accurate coverage of commonly encountered tumors along their routes of spread This handbook is designed to enable radiation oncologists to appropriately and confidently delineate tumor volumes/fields for conformal radiation therapy, including intensity-modulated radiation therapy (IMRT), in patients with commonly encountered cancers The orientation of this handbook is entirely practical, in that the focus is on the illustration of clinical target volume (CTV) delineation for each major malignancy Each chapter provides guidelines and concise knowledge on CTV selection for a particular disease, explains how the anatomy of lymphatic drainage shapes the selection of the target volume, and presents detailed illustrations of volumes, slice by slice, on planning CT images While the emphasis is on target volume delineation for three-dimensional conformal therapy and IMRT, information is also provided on conventional radiation therapy field setup and planning for certain malignancies for which IMRT is not currently suitable},
note={RADIOLOGY AND NUCLEAR MEDICINE},
isbn={978-3-642-28859-3},
url={http://inis.iaea.org/search/search.aspx?orig_q=RN:44039493}
}

@ARTICLE{Lin:2015,
  title    = "Treatment of Brain Metastases",
  author   = "Lin, Xuling and DeAngelis, Lisa M",
  abstract = "Brain metastases (BMs) occur in 10\% to 20\% of adult patients
              with cancer, and with increased surveillance and improved
              systemic control, the incidence is likely to grow. Despite
              multimodal treatment, prognosis remains poor. Current evidence
              supports use of whole-brain radiation therapy when patients
              present with multiple BMs. However, its associated cognitive
              impairment is a major deterrent in patients likely to live longer
              than 6 months. In patients with oligometastases (one to three
              metastases) and even some with multiple lesions less than 3 to 4
              cm, especially if the primary tumor is considered radiotherapy
              resistant, stereotactic radiosurgery is recommended; if the BMs
              are greater than 4 cm, surgical resection with or without
              postoperative whole-brain radiation therapy should be considered.
              There is increasing evidence that systemic therapy, including
              targeted therapy and immunotherapy, is effective against BM and
              may be an early choice, especially in patients with sensitive
              primary tumors. In patients with progressive systemic disease,
              limited treatment options, and poor performance status, best
              supportive care may be appropriate. Regardless of treatment
              goals, use of corticosteroids or antiepileptic medications is
              helpful in symptomatic patients. In this review, we provide a
              summary of current therapy, as well as developments in the
              treatment of BM from solid tumors.",
  journal  = "J Clin Oncol",
  volume   =  33,
  number   =  30,
  pages    = "3475--3484",
  month    =  aug,
  year     =  2015,
  address  = "United States",
  language = "en"
}

@ARTICLE{Tsao:2012,
  title    = "Radiotherapeutic and surgical management for newly diagnosed
              brain metastasis(es): An American Society for Radiation Oncology
              evidence-based guideline",
  author   = "Tsao, May N and Rades, Dirk and Wirth, Andrew and Lo, Simon S and
              Danielson, Brita L and Gaspar, Laurie E and Sperduto, Paul W and
              Vogelbaum, Michael A and Radawski, Jeffrey D and Wang, Jian Z and
              Gillin, Michael T and Mohideen, Najeeb and Hahn, Carol A and
              Chang, Eric L",
  abstract = "PURPOSE: To systematically review the evidence for the
              radiotherapeutic and surgical management of patients newly
              diagnosed with intraparenchymal brain metastases. METHODS AND
              MATERIALS: Key clinical questions to be addressed in this
              evidence-based Guideline were identified. Fully published
              randomized controlled trials dealing with the management of newly
              diagnosed intraparenchymal brain metastases were searched
              systematically and reviewed. The U.S. Preventative Services Task
              Force levels of evidence were used to classify various options of
              management. RESULTS: The choice of management in patients with
              newly diagnosed single or multiple brain metastases depends on
              estimated prognosis and the aims of treatment (survival, local
              treated lesion control, distant brain control, neurocognitive
              preservation). Single brain metastasis and good prognosis
              (expected survival 3 months or more): For a single brain
              metastasis larger than 3 to 4 cm and amenable to safe complete
              resection, whole brain radiotherapy (WBRT) and surgery (level 1)
              should be considered. Another alternative is surgery and
              radiosurgery/radiation boost to the resection cavity (level 3).
              For single metastasis less than 3 to 4 cm, radiosurgery alone or
              WBRT and radiosurgery or WBRT and surgery (all based on level 1
              evidence) should be considered. Another alternative is surgery
              and radiosurgery or radiation boost to the resection cavity
              (level 3). For single brain metastasis (less than 3 to 4 cm) that
              is not resectable or incompletely resected, WBRT and
              radiosurgery, or radiosurgery alone should be considered (level
              1). For nonresectable single brain metastasis (larger than 3 to 4
              cm), WBRT should be considered (level 3). Multiple brain
              metastases and good prognosis (expected survival 3 months or
              more): For selected patients with multiple brain metastases (all
              less than 3 to 4 cm), radiosurgery alone, WBRT and radiosurgery,
              or WBRT alone should be considered, based on level 1 evidence.
              Safe resection of a brain metastasis or metastases causing
              significant mass effect and postoperative WBRT may also be
              considered (level 3). Patients with poor prognosis (expected
              survival less than 3 months): Patients with either single or
              multiple brain metastases with poor prognosis should be
              considered for palliative care with or without WBRT (level 3). It
              should be recognized, however, that there are limitations in the
              ability of physicians to accurately predict patient survival.
              Prognostic systems such as recursive partitioning analysis, and
              diagnosis-specific graded prognostic assessment may be helpful.
              CONCLUSIONS: Radiotherapeutic intervention (WBRT or radiosurgery)
              is associated with improved brain control. In selected patients
              with single brain metastasis, radiosurgery or surgery has been
              found to improve survival and locally treated metastasis control
              (compared with WBRT alone).",
  journal  = "Pract Radiat Oncol",
  volume   =  2,
  number   =  3,
  pages    = "210--225",
  month    =  jan,
  year     =  2012,
  address  = "United States",
  language = "en"
}

@techreport{icru50:2015,
  author      = "ICRU",
  title       = "Prescribing, Recording, and Reporting Photon Beam Therapy",
  institution = "Internacional Comission on Radiation Units and Measurements",
  year        = "2015",
  address     = "7910 Woodmont Avenue, Suite 800, Bethesda, Maryland 20814, U.S.A."
}

@ARTICLE{Scoccianti:2015,
  title    = "Organs at risk in the brain and their dose-constraints in adults
              and in children: a radiation oncologist's guide for delineation
              in everyday practice",
  author   = "Scoccianti, Silvia and Detti, Beatrice and Gadda, Davide and
              Greto, Daniela and Furfaro, Ilaria and Meacci, Fiammetta and
              Simontacchi, Gabriele and Di Brina, Lucia and Bonomo, Pierluigi
              and Giacomelli, Irene and Meattini, Icro and Mangoni, Monica and
              Cappelli, Sabrina and Cassani, Sara and Talamonti, Cinzia and
              Bordi, Lorenzo and Livi, Lorenzo",
  abstract = "PURPOSE: Accurate organs at risk definition is essential for
              radiation treatment of brain tumors. The aim of this study is to
              provide a stepwise and simplified contouring guide to delineate
              the OARs in the brain as it would be done in the everyday
              practice of planning radiotherapy for brain cancer treatment.
              METHODS: Anatomical descriptions and neuroimaging atlases of the
              brain were studied. The dosimetric constraints used in literature
              were reviewed. RESULTS: A Computed Tomography and Magnetic
              Resonance Imaging based detailed atlas was developed jointly by
              radiation oncologists, a neuroradiologist and a neurosurgeon. For
              each organ brief anatomical notion, main radiological reference
              points and useful considerations are provided. Recommended
              dose-constraints both for adult and pediatric patients were also
              provided. CONCLUSIONS: This report provides guidelines for OARs
              delineation and their dose-constraints for the treatment planning
              of patients with brain tumors.",
  journal  = "Radiother Oncol",
  volume   =  114,
  number   =  2,
  pages    = "230--238",
  month    =  feb,
  year     =  2015,
  address  = "Ireland",
  keywords = "Brain contouring atlas; Dose-constraints; Normal tissue; Optic
              chiasm; Organs at risk; Radiotherapy atlas",
  language = "en"
}

@ARTICLE{Badloe:2021,
  title    = "Impact of {PTV} margin reduction (2 mm to 0 mm) on
              pseudoprogression in stereotactic radiotherapy of solitary brain
              metastases",
  author   = "Badloe, Justine and Mast, Mirjam and Petoukhova, Anna and
              Franssen, Jan-Huib and Ghariq, Elyas and van der Voort van Zijp,
              No{\"e}lle and Wiggenraad, Ruud",
  abstract = "PURPOSE: To determine the influence of PTV-margin (0 mm versus 2
              mm) on the incidence of pseudoprogression (PP) and local tumour
              control (LC) in patients treated with stereotactic radiotherapy
              (SRT) for solitary brain metastases. METHODS: Patients were
              treated on Novalis LINAC. Three dose schedules were used
              depending on the PTV-size. The PTV-margin was 2-mm prior to 2015
              and 0-mm thereafter. MRI-scans were made every three months
              including a perfusion MRI-scan when pseudoprogression was
              suspected. We examined the relation of pseudoprogression and
              local control with the size of PTV-margin. Besides this, the
              association of dose-volume data of the whole brain (minus GTV)
              and pseudoprogression was investigated. RESULTS: 121 patients
              were analyzed (2-mm margin in 84 patients; 0-mm margin in 37
              patients). There was no difference in GTV (7.6 cc versus 9.1 cc p
              = 0.2). At 24 months there was no difference in incidence of
              pseudoprogression (49\% and versus 33\%, p = 0.5) and local
              control in the 2-mm and 0-mm group (82\% and versus 79\%, p =
              1.0). The size of PTV-margin was not associated with PP. Both
              margin and volume of brain receiving 12 Gy (V12) were not
              associated with pseudoprogression in patients treated with single
              fraction. CONCLUSIONS: PTV-margin reduction did not reduce the
              incidence of pseudoprogression in LINAC-based-SRT for single
              brain metastases. We did not find a significant association of
              GTV-PTV margin or V12Gy with the incidence of pseudoprogression
              in solitary metastases treated with a single fraction. LC rates
              were similar, indicating margin reduction seems to be safe.",
  journal  = "Tech Innov Patient Support Radiat Oncol",
  volume   =  17,
  pages    = "40--47",
  month    =  mar,
  year     =  2021,
  address  = "England",
  keywords = "Brain metastases; Margins; Pseudoprogression; Stereotactic
              radiotherapy",
  language = "en"
}

@ARTICLE{Siddique:2020,
  title    = "Artificial intelligence in radiotherapy",
  author   = "Siddique, Sarkar and Chow, James C L",
  abstract = "Artificial intelligence (AI) has already been implemented widely
              in the medical field in the recent years. This paper first
              reviews the background of AI and radiotherapy. Then it explores
              the basic concepts of different AI algorithms and machine
              learning methods, such as neural networks, that are available to
              us today and how they are being implemented in radiotherapy and
              diagnostic processes, such as medical imaging, treatment
              planning, patient simulation, quality assurance and radiation
              dose delivery. It also explores the ongoing research on AI
              methods that are to be implemented in radiotherapy in the future.
              The review shows very promising progress and future for AI to be
              widely used in various areas of radiotherapy. However, basing on
              various concerns such as availability and security of using big
              data, and further work on polishing and testing AI algorithms, it
              is found that we may not ready to use AI primarily in
              radiotherapy at the moment.",
  journal  = "Rep Pract Oncol Radiother",
  volume   =  25,
  number   =  4,
  pages    = "656--666",
  month    =  may,
  year     =  2020,
  address  = "Poland",
  keywords = "Artificial intelligence; Machine learning; Medical imaging;
              Radiotherapy",
  language = "en"
}

@ARTICLE{Chen:2018,
  title    = "A feasibility study on an automated method to generate
              patient-specific dose distributions for radiotherapy using deep
              learning",
  author   = "Chen, Xinyuan and Men, Kuo and Li, Yexiong and Yi, Junlin and
              Dai, Jianrong",
  abstract = "PURPOSE: To develop a method for predicting optimal dose
              distributions, given the planning image and segmented anatomy, by
              applying deep learning techniques to a database of previously
              optimized and approved Intensity-modulated radiation therapy
              treatment plans. METHODS: Eighty cases of early-stage
              nasopharyngeal cancer (NPC) were included in the study. Seventy
              cases were chosen randomly as the training set and the remaining
              as the test set. The inputs were the images with structures, with
              each target and organs at risk (OARs) assigned a unique label.
              The outputs were dose maps, including coarse dose maps and
              converted fine dose maps (FDM) from convolution. Two types of
              input images with structures were used in the model building. One
              type of input included the images (with associated structures)
              without manipulation. The second type of input involved modifying
              the image gray label with information from radiation beam
              geometry. ResNet101 was chosen as the deep learning network for
              both. The accuracy of predicted dose distributions was evaluated
              against the corresponding dose as used in the clinic. A global
              three-dimensional gamma analysis was calculated for the
              evaluation. RESULTS: The proposed model trained with the two
              different sets of input images and structures could both predict
              patient-specific dose distributions accurately. For the
              out-of-field dose distributions, the model obtained from the
              input with radiation geometry performed better (dose difference
              in \%, 4.7 $\pm$ 6.1\% vs 5.5 $\pm$ 7.9\%, P 0.05), except for
              the bilateral optic nerves and the optic chiasm. CONCLUSIONS: The
              proposed system with radiation geometry added to the input is a
              promising method to generate patient-specific dose distributions
              for radiotherapy. It can be applied to obtain the dose
              distributions slice-by-slice for planning quality assurance and
              for guiding automated planning.",
  journal  = "Med Phys",
  volume   =  46,
  number   =  1,
  pages    = "56--64",
  month    =  nov,
  year     =  2018,
  address  = "United States",
  keywords = "automatic; deep learning; dose prediction; radiotherapy;
              treatment planning",
  language = "en"
}


@ARTICLE{Chen:2021,
  title    = "{DVHnet}: A deep learning-based prediction of patient-specific
              dose volume histograms for radiotherapy planning",
  author   = "Chen, Xinyuan and Men, Kuo and Zhu, Ji and Yang, Bining and Li,
              Minghui and Liu, Zhiqiang and Yan, Xuena and Yi, Junlin and Dai,
              Jianrong",
  abstract = "PURPOSE: To develop a deep learning method to predict
              patient-specific dose volume histograms (DVHs) for radiotherapy
              planning. METHODS: Patient data included 180 cases with
              nasopharyngeal cancer, of which 153 cases were used for training
              and 27 for testing. A network (named ``DVHnet'') based on a
              convolutional neural network (CNN) was designed for directly
              predicting DVHs of organs at risk (OARs). Two-channel images with
              contoured structures were generated as the inputs for training
              the model. A one-dimensional array consisting of 256 continuous
              volume percentages on a DVH curve for each slice was calculated
              as the corresponding output. The combined DVH was then
              calculated. Sixteen OARs were modeled in the study. Prediction
              accuracy was evaluated against the corresponding DVH curve of
              ground truth (GT) plans. A global DVH analysis and critical
              dosimetry metrics for each OAR were calculated for quantitative
              evaluation. The performance of DVHnet also was evaluated against
              two baselines: DosemapNet (developed by our research group) and
              commercial RapidPlan software. RESULTS: The predicted mean
              difference in average dose of all OARs using DVHnet was 0.30
              $\pm$ 0.95 Gy. And the predicted differences in D2\% and D50 can
              be control within 2.32 and 0.69 Gy. For most OARs, there were no
              obvious differences between the dosimetric metrics of the
              predicted and GT values for both DVHnet and DosemapNet (P $\geq$
              0.05). Only the predicted D2\% of the optic organs for DVHnet,
              and of brain stem PRV for DosemapNet displayed statistically
              significant differences. Except for the optic organs, DVHnet
              performs better than or comparably with RapidPlan. The mean
              difference in proportion of points of interest was 3.59\% $\pm$
              7.78\%. CONCLUSIONS: A deep learning network model was developed
              to automatically extract useful features for accurate prediction
              of patient-specific DVH curves directly. The performance of
              DVHnet was comparable to DosemapNet and RapidPlan.",
  journal  = "Med Phys",
  volume   =  48,
  number   =  6,
  pages    = "2705--2713",
  month    =  apr,
  year     =  2021,
  address  = "United States",
  keywords = "automatic; deep learning; dose volume histogram; knowledge-based
              radiotherapy planning",
  language = "en"
}

@ARTICLE{Fan:2018,
  title    = "Automatic treatment planning based on three-dimensional dose
              distribution predicted from deep learning technique",
  author   = "Fan, Jiawei and Wang, Jiazhou and Chen, Zhi and Hu, Chaosu and
              Zhang, Zhen and Hu, Weigang",
  abstract = "PURPOSE: To develop an automated treatment planning strategy for
              external beam intensity-modulated radiation therapy (IMRT),
              including a deep learning-based three-dimensional (3D) dose
              prediction and a dose distribution-based plan generation
              algorithm. METHODS AND MATERIALS: A residual neural network-based
              deep learning model is trained to predict a dose distribution
              based on patient-specific geometry and prescription dose. A total
              of 270 head-and-neck cancer cases were enrolled in this study,
              including 195 cases in the training dataset, 25 cases in the
              validation dataset, and 50 cases in the testing dataset. All
              patients were treated with IMRT with a variety of different
              prescription patterns. The model input consists of CT images and
              contours delineating the organs at risk (OARs) and planning
              target volumes (PTVs). The algorithm output is trained to predict
              the dose distribution on the CT image slices. The obtained
              prediction model is used to predict dose distributions for new
              patients. Then, an optimization objective function based on these
              predicted dose distributions is created for automatic plan
              generation. RESULTS: Our results demonstrate that the deep
              learning method can predict clinically acceptable dose
              distributions. There is no statistically significant difference
              between prediction and real clinical plan for all clinically
              relevant dose-volume histogram (DVH) indices, except brainstem,
              right and left lens. However, the predicted plans were still
              clinically acceptable. The results of plan generation show no
              statistically significant differences between the automatic
              generated plan and the predicted plan except PTV(70.4) , but the
              difference is only 0.5\% which is still clinically acceptable.
              CONCLUSION: This study developed a new automated radiotherapy
              treatment planning system based on 3D dose prediction and 3D dose
              distribution-based optimization. It is a promising approach for
              realizing automated treatment planning in the future.",
  journal  = "Med Phys",
  volume   =  46,
  number   =  1,
  pages    = "370--381",
  month    =  nov,
  year     =  2018,
  address  = "United States",
  keywords = "deep learning; dose distribution prediction; knowledge-based
              planning; voxel-by-voxel dose optimization",
  language = "en"
}

@InProceedings{Hu:2019,
author="Hu, Szu-Yeu
and Weng, Wei-Hung
and Lu, Shao-Lun
and Cheng, Yueh-Hung
and Xiao, Furen
and Hsu, Feng-Ming
and Lu, Jen-Tang",
editor="Nguyen, Dan
and Xing, Lei
and Jiang, Steve",
title="Multimodal Volume-Aware Detection and Segmentation for Brain Metastases Radiosurgery",
booktitle="Artificial Intelligence in Radiation Therapy",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="61--69",
abstract="Stereotactic radiosurgery (SRS), which delivers high doses of irradiation in a single or few shots to small targets, has been a standard of care for brain metastases. While very effective, SRS currently requires manually intensive delineation of tumors. In this work, we present a deep learning approach for automated detection and segmentation of brain metastases using multimodal imaging and ensemble neural networks. In order to address small and multiple brain metastases, we further propose a volume-aware Dice loss which optimizes model performance using the information of lesion size. This work surpasses current benchmark levels and demonstrates a reliable AI-assisted system for SRS treatment planning for multiple brain metastases.",
isbn="978-3-030-32486-5"
}

@article{Rudie:2021,
author = {Rudie, Jeffrey D. and Weiss, David A. and Colby, John B. and Rauschecker, Andreas M. and Laguna, Benjamin and Braunstein, Steve and Sugrue, Leo P. and Hess, Christopher P. and Villanueva-Meyer, Javier E.},
title = {Three-dimensional U-Net Convolutional Neural Network for Detection and Segmentation of Intracranial Metastases},
journal = {Radiology: Artificial Intelligence},
volume = {3},
number = {3},
pages = {e200204},
year = {2021},
doi = {10.1148/ryai.2021200204},
URL = {https://doi.org/10.1148/ryai.2021200204},
eprint = {https://doi.org/10.1148/ryai.2021200204}
,
    abstract = { Purpose To develop and validate a neural network for automated detection and segmentation of intracranial metastases on brain MRI studies obtained for stereotactic radiosurgery treatment planning. Materials and Methods In this retrospective study, 413 patients (average age, 61 years ± 12 [standard deviation]; 238 women) with a total of 5202 intracranial metastases (median volume, 0.05 cm3; interquartile range, 0.02–0.18 cm3) undergoing stereotactic radiosurgery at one institution were included (January 2017 to February 2020). A total of 563 MRI examinations were performed among the patients, and studies were split into training (n = 413), validation (n = 50), and test (n = 100) datasets. A three-dimensional (3D) U-Net convolutional network was trained and validated on 413 T1 postcontrast or subtraction scans, and several loss functions were evaluated. After model validation, 100 discrete test patients, who underwent imaging after the training and validation patients, were used for final model evaluation. Performance for detection and segmentation of metastases was evaluated using Dice scores, false discovery rates, and false-negative rates, and a comparison with neuroradiologist interrater reliability was performed. Results The median Dice score for segmenting enhancing metastases in the test set was 0.75 (interquartile range, 0.63–0.84). There were strong correlations between manually segmented and predicted metastasis volumes (r = 0.98, P < .001) and between the number of manually segmented and predicted metastases (R = 0.95, P < .001). Higher Dice scores were strongly correlated with larger metastasis volumes on a logarithmically transformed scale (r = 0.71). Sensitivity across the whole test sample was 70.0\% overall and 96.4\% for metastases larger than 6 mm. There was an average of 0.46 false-positive results per scan, with the positive predictive value being 91.5\%. In comparison, the median Dice score between two neuroradiologists was 0.85 (interquartile range, 0.80–0.89), with sensitivity across the test sample being 87.9\% overall and 98.4\% for metastases larger than 6 mm. Conclusion A 3D U-Net–based convolutional neural network was able to segment brain metastases with high accuracy and perform detection at the level of human interrater reliability for metastases larger than 6 mm. Keywords: Adults, Brain/Brain Stem, CNS, Feature detection, MR-Imaging, Neural Networks, Neuro-Oncology, Quantification, Segmentation ©RSNA, 2021 }
}

@incollection{Bibault:2021,
title = {Chapter 18 - Artificial intelligence in oncology},
editor = {Lei Xing and Maryellen L. Giger and James K. Min},
booktitle = {Artificial Intelligence in Medicine},
publisher = {Academic Press},
pages = {361-381},
year = {2021},
isbn = {978-0-12-821259-2},
doi = {https://doi.org/10.1016/B978-0-12-821259-2.00018-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128212592000181},
author = {Jean-Emmanuel Bibault and Anita Burgun and Laure Fournier and André Dekker and Philippe Lambin},
keywords = {Oncology, cancer, artificial intelligence, deep learning, machine learning, prediction},
abstract = {Medical decisions can rely on a very large number of parameters, but it is traditionally considered that our cognitive capacity can only integrate up to five factors in order to take a decision. Oncologists will need to combine vast amount of clinical, biological, and imaging data to achieve state-of-the-art treatments. Data science and artificial intelligence (AI) will have an important role in the generation of models to predict outcome and guide treatments. A new paradigm of data-driven decision-making, reusing routine health-care data to provide decision support is emerging. This chapter explores the studies published in imaging, medical and radiation oncology and explains the technical challenges that need to be addressed before AI can be routinely used to treat cancer patients.}
}

@INCOLLECTION{Amsbaugh:2023,
  title     = "Brain Metastasis",
  booktitle = "{StatPearls}",
  author    = "Amsbaugh, Mark J and Kim, Catherine S",
  abstract  = "Brain metastases are a common complication of cancer and the
               most common type of brain tumor. Anywhere from 10\% to 26\% of
               patients who die from their cancer will develop brain
               metastases. While few cancers that metastasize to the brain can
               be cured using conventional therapies, long-term survival and
               palliation are possible with minimal adverse effects to
               patients. Increasingly, neuro-cognition and quality of life are
               being recognized as important endpoints for patients as survival
               continues to increase.",
  publisher = "StatPearls Publishing",
  month     =  jan,
  year      =  2023,
  address   = "Treasure Island (FL)",
  language  = "en"
}

@article{Charron:2018,
title = {Automatic detection and segmentation of brain metastases on multimodal MR images with a deep convolutional neural network},
journal = {Computers in Biology and Medicine},
volume = {95},
pages = {43-54},
year = {2018},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518300325},
author = {Odelin Charron and Alex Lallement and Delphine Jarnet and Vincent Noblet and Jean-Baptiste Clavier and Philippe Meyer},
keywords = {Brain metastases, Magnetic resonance imaging, Convolutional neural network, Detection, Segmentation},
abstract = {Stereotactic treatments are today the reference techniques for the irradiation of brain metastases in radiotherapy. The dose per fraction is very high, and delivered in small volumes (diameter <1 cm). As part of these treatments, effective detection and precise segmentation of lesions are imperative. Many methods based on deep-learning approaches have been developed for the automatic segmentation of gliomas, but very little for that of brain metastases. We adapted an existing 3D convolutional neural network (DeepMedic) to detect and segment brain metastases on MRI. At first, we sought to adapt the network parameters to brain metastases. We then explored the single or combined use of different MRI modalities, by evaluating network performance in terms of detection and segmentation. We also studied the interest of increasing the database with virtual patients or of using an additional database in which the active parts of the metastases are separated from the necrotic parts. Our results indicated that a deep network approach is promising for the detection and the segmentation of brain metastases on multimodal MRI.}
}

@ARTICLE{BRATS:2015,
  author={Menze, Bjoern H. and Jakab, Andras and Bauer, Stefan and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and Wiest, Roland and Lanczi, Levente and Gerstner, Elizabeth and Weber, Marc-André and Arbel, Tal and Avants, Brian B. and Ayache, Nicholas and Buendia, Patricia and Collins, D. Louis and Cordier, Nicolas and Corso, Jason J. and Criminisi, Antonio and Das, Tilak and Delingette, Hervé and Demiralp, Cagatay and Durst, Christopher R. and Dojat, Michel and Doyle, Senan and Festa, Joana and Forbes, Florence and Geremia, Ezequiel and Glocker, Ben and Golland, Polina and Guo, Xiaotao and Hamamci, Andac and Iftekharuddin, Khan M. and Jena, Raj and John, Nigel M. and Konukoglu, Ender and Lashkari, Danial and Mariz, José António and Meier, Raphael and Pereira, Sérgio and Precup, Doina and Price, Stephen J. and Raviv, Tammy Riklin and Reza, Syed M. S. and Ryan, Michael and Sarikaya, Duygu and Schwartz, Lawrence and Shin, Hoo-Chang and Shotton, Jamie and Silva, Carlos A. and Sousa, Nuno and Subbanna, Nagesh K. and Szekely, Gabor and Taylor, Thomas J. and Thomas, Owen M. and Tustison, Nicholas J. and Unal, Gozde and Vasseur, Flor and Wintermark, Max and Ye, Dong Hye and Zhao, Liang and Zhao, Binsheng and Zikic, Darko and Prastawa, Marcel and Reyes, Mauricio and Van Leemput, Koen},
  journal={IEEE Transactions on Medical Imaging}, 
  title={The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)}, 
  year={2015},
  volume={34},
  number={10},
  pages={1993-2024},
  doi={10.1109/TMI.2014.2377694}}

@ARTICLE{Liu:2017,
  title    = "A deep convolutional neural network-based automatic delineation
              strategy for multiple brain metastases stereotactic radiosurgery",
  author   = "Liu, Yan and Stojadinovic, Strahinja and Hrycushko, Brian and
              Wardak, Zabi and Lau, Steven and Lu, Weiguo and Yan, Yulong and
              Jiang, Steve B and Zhen, Xin and Timmerman, Robert and Nedzi,
              Lucien and Gu, Xuejun",
  abstract = "Accurate and automatic brain metastases target delineation is a
              key step for efficient and effective stereotactic radiosurgery
              (SRS) treatment planning. In this work, we developed a deep
              learning convolutional neural network (CNN) algorithm for
              segmenting brain metastases on contrast-enhanced T1-weighted
              magnetic resonance imaging (MRI) datasets. We integrated the
              CNN-based algorithm into an automatic brain metastases
              segmentation workflow and validated on both Multimodal Brain
              Tumor Image Segmentation challenge (BRATS) data and clinical
              patients' data. Validation on BRATS data yielded average DICE
              coefficients (DCs) of 0.75$\pm$0.07 in the tumor core and
              0.81$\pm$0.04 in the enhancing tumor, which outperformed most
              techniques in the 2015 BRATS challenge. Segmentation results of
              patient cases showed an average of DCs 0.67$\pm$0.03 and achieved
              an area under the receiver operating characteristic curve of
              0.98$\pm$0.01. The developed automatic segmentation strategy
              surpasses current benchmark levels and offers a promising tool
              for SRS treatment planning for multiple brain metastases.",
  journal  = "PLoS One",
  volume   =  12,
  number   =  10,
  pages    = "e0185844",
  month    =  oct,
  year     =  2017,
  address  = "United States",
  language = "en"
}

@ARTICLE{Mori:2006,
  title    = "Stereotactic imaging for radiosurgery: localization accuracy of
              magnetic resonance imaging and positron emission tomography
              compared with computed tomography",
  author   = "Mori, Yoshimasa and Hayashi, Naoki and Iwase, Mikio and Yamada,
              Masami and Takikawa, Yukinori and Uchiyama, Yukio and Oda, Kyota
              and Kaii, Osamu",
  abstract = "Computed tomography (CT), magnetic resonance imaging (MRI), and
              positron emission tomography (PET) provide complementary
              information for treatment planning in stereotactic radiosurgery.
              We evaluated the localization accuracy of MRI and PET compared
              with CT. Two kinds of phantoms applicable to the Leksell G
              stereotactic skull frame (Elekta, Tokyo) were developed.
              Deviations of measured coordinates at target points (x = 50, 100,
              150; y = 50, 100, 150) were determined on different axial planes
              (z = 30-140 for MRI and CT study and Z = 50-120 for PET and CT
              study). For MRI, the deviations were no more than 0.8 mm in each
              direction. For PET, the deviations were no more than 2.7 mm. For
              both imaging modalities studied, accuracy was at or below the
              imaging resolution (pixel size) and should be considered useful
              for clinical stereotactic planning purposes.",
  journal  = "Stereotact Funct Neurosurg",
  volume   =  84,
  number   =  4,
  pages    = "142--146",
  month    =  aug,
  year     =  2006,
  address  = "Switzerland",
  language = "en"
}

@ARTICLE{Castellano:2021,
  title    = "Advanced imaging techniques for radiotherapy planning of gliomas",
  author   = "Castellano, Antonella and Bailo, Michele and Cicone, Francesco
              and Carideo, Luciano and Quartuccio, Natale and Mortini, Pietro
              and Falini, Andrea and Cascini, Giuseppe Lucio and Minniti,
              Giuseppe",
  abstract = "The accuracy of target delineation in radiation treatment (RT)
              planning of cerebral gliomas is crucial to achieve high tumor
              control, while minimizing treatment-related toxicity.
              Conventional magnetic resonance imaging (MRI), including
              contrast-enhanced T1-weighted and fluid-attenuated inversion
              recovery (FLAIR) sequences, represents the current standard
              imaging modality for target volume delineation of gliomas.
              However, conventional sequences have limited capability to
              discriminate treatment-related changes from viable tumors, owing
              to the low specificity of increased blood-brain barrier
              permeability and peritumoral edema. Advanced physiology-based MRI
              techniques, such as MR spectroscopy, diffusion MRI and perfusion
              MRI, have been developed for the biological characterization of
              gliomas and may circumvent these limitations, providing
              additional metabolic, structural, and hemodynamic information for
              treatment planning and monitoring. Radionuclide imaging
              techniques, such as positron emission tomography (PET) with amino
              acid radiopharmaceuticals, are also increasingly used in the
              workup of primary brain tumors, and their integration in RT
              planning is being evaluated in specialized centers. This review
              focuses on the basic principles and clinical results of advanced
              MRI and PET imaging techniques that have promise as a complement
              to RT planning of gliomas.",
  journal  = "Cancers (Basel)",
  volume   =  13,
  number   =  5,
  month    =  mar,
  year     =  2021,
  keywords = "FET; PET; advanced MRI; amino acid radiopharmaceuticals;
              diffusion-weighted imaging; glioma; hypoxia; magnetic resonance
              spectroscopy; perfusion-weighted imaging; radiation treatment
              planning",
  language = "en"
}

@Article{Demiral:2019,
  author={Selcuk Demiral and Omer Sager and Ferrat Dincoglan and Murat Beyzadeoglu},
  title={{Assessment of Computed Tomography (CT) And Magnetic Resonance Imaging (MRI) Based Radiosurgery Treatment Planning for Pituitary Adenomas}},
  journal={Cancer Therapy \& Oncology International Journal},
  year=2019,
  volume={13},
  number={2},
  pages={59-62},
  month={March},
  keywords={juniper publishers:oncology journals; oncology research journals; oncology journal articles; oncolog},
  doi={10.19080/CTOIJ.2019.13.55},
  abstract={Pituitary adenomas are fairly common benign tumors which may be found in up to 20\% of the general population. While a considerable proportion of patients harboring these benign tumors may be asymptomatic, symptoms may arise due to the mass effect on critical neurovascular structures including the optic nerves and chiasm, cavernous sinus, and normally functioning pituitary gland or stalk. Radiosurgery may be used as a viable therapeutic option for management of pituitary adenomas},
  url={https://ideas.repec.org/a/adp/jctoij/v13y2019i2p59-62.html}
}

@ARTICLE{Bidgood:1997,
  title    = "Understanding and using {DICOM}, the data interchange standard
              for biomedical imaging",
  author   = "Bidgood, Jr, W D and Horii, S C and Prior, F W and Van Syckle, D
              E",
  abstract = "The Digital Imaging and Communications in Medicine (DICOM)
              Standard specifies a non-proprietary data interchange protocol,
              digital image format, and file structure for biomedical images
              and image-related information. The fundamental concepts of the
              DICOM message protocol, services, and information objects are
              reviewed as background for a detailed discussion of the
              functionality of DICOM; the innovations and limitations of the
              Standard; and the impact of various DICOM features on information
              system users. DICOM addresses five general application areas: (1)
              network image management, (2) network image interpretation
              management, (3) network print management, (4) imaging procedure
              management, (5) off-line storage media management. DICOM is a
              complete specification of the elements required to achieve a
              practical level of automatic interoperability between biomedical
              imaging computer systems--from application layer to bit-stream
              encoding. The Standard is being extended and expanded in modular
              fashion to support new applications and incorporate new
              technology. An interface to other Information Systems provides
              for shared management of patient, procedure, and results
              information related to images. A Conformance Statement template
              enables a knowledgeable user to determine if interoperability
              between two implementations is possible. Knowledge of DICOM's
              benefits and realistic understanding of its limitations enable
              one to use the Standard effectively as the basis for a long term
              implementation strategy for image management and communications
              systems.",
  journal  = "J Am Med Inform Assoc",
  volume   =  4,
  number   =  3,
  pages    = "199--212",
  month    =  may,
  year     =  1997,
  address  = "England",
  language = "en"
}

@article{Andersen:2022, doi = {10.21105/joss.04133}, url = {https://doi.org/10.21105/joss.04133}, year = {2022}, publisher = {The Open Journal}, volume = {7}, number = {73}, pages = {4133}, author = {Erling Andersen}, title = {Imagedata: A Python library to handle medical image data in NumPy array subclass Series}, journal = {Journal of Open Source Software} }

@article{Mason:2011,
  title={SU-E-T-33: Pydicom: An Open Source DICOM Library},
  author={D Mason},
  journal={Medical Physics},
  year={2011},
  volume={38},
  pages={3493-3493}
}

@Article{Yamashita:2018,
author={Yamashita, Rikiya
and Nishio, Mizuho
and Do, Richard Kinh Gian
and Togashi, Kaori},
title={Convolutional neural networks: an overview and application in radiology},
journal={Insights into Imaging},
year={2018},
month={Aug},
day={01},
volume={9},
number={4},
pages={611-629},
abstract={Convolutional neural network (CNN), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of CNN and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying CNN to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of CNN is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care.},
issn={1869-4101},
doi={10.1007/s13244-018-0639-9},
url={https://doi.org/10.1007/s13244-018-0639-9}
}

@Article{Bousabarah:2020,
author={Bousabarah, Khaled
and Ruge, Maximilian
and Brand, Julia-Sarita
and Hoevels, Mauritius
and Rue{\ss}, Daniel
and Borggrefe, Jan
and Gro{\ss}e Hokamp, Nils
and Visser-Vandewalle, Veerle
and Maintz, David
and Treuer, Harald
and Kocher, Martin},
title={Deep convolutional neural networks for automated segmentation of brain metastases trained on clinical data},
journal={Radiation Oncology},
year={2020},
month={Apr},
day={20},
volume={15},
number={1},
pages={87},
abstract={Deep learning-based algorithms have demonstrated enormous performance in segmentation of medical images. We collected a dataset of multiparametric MRI and contour data acquired for use in radiosurgery, to evaluate the performance of deep convolutional neural networks (DCNN) in automatic segmentation of brain metastases (BM).},
issn={1748-717X},
doi={10.1186/s13014-020-01514-6},
url={https://doi.org/10.1186/s13014-020-01514-6}
}

@ARTICLE{Dikici:2020,
  title    = "Automated Brain Metastases Detection Framework for {T1-Weighted}
              {Contrast-Enhanced} {3D} {MRI}",
  author   = "Dikici, Engin and Ryu, John L and Demirer, Mutlu and Bigelow,
              Matthew and White, Richard D and Slone, Wayne and Erdal, Barbaros
              Selnur and Prevedello, Luciano M",
  abstract = "Brain Metastases (BM) complicate 20-40\% of cancer cases. BM
              lesions can present as punctate (1 mm) foci, requiring
              high-precision Magnetic Resonance Imaging (MRI) in order to
              prevent inadequate or delayed BM treatment. However, BM lesion
              detection remains challenging partly due to their structural
              similarities to normal structures (e.g., vasculature). We propose
              a BM-detection framework using a single-sequence
              gadolinium-enhanced T1-weighted 3D MRI dataset. The framework
              focuses on the detection of smaller (<15 mm) BM lesions and
              consists of: (1) candidate-selection stage, using Laplacian of
              Gaussian approach for highlighting parts of an MRI volume holding
              higher BM occurrence probabilities, and (2) detection stage that
              iteratively processes cropped region-of-interest volumes centered
              by candidates using a custom-built 3D convolutional neural
              network (``CropNet''). Data is augmented extensively during
              training via a pipeline consisting of random ga mma correction
              and elastic deformation stages; the framework thereby maintains
              its invariance for a plausible range of BM shape and intensity
              representations. This approach is tested using five-fold
              cross-validation on 217 datasets from 158 patients, with training
              and testing groups randomized per patient to eliminate learning
              bias. The BM database included lesions with a mean diameter of
              ∼5.4 mm and a mean volume of ∼160 mm(3). For 90\% BM-detection
              sensitivity, the framework produced on average 9.12
              false-positive BM detections per patient (standard deviation of
              3.49); for 85\% sensitivity, the average number of
              false-positives declined to 5.85. Comparative analysis showed
              that the framework produces comparable BM-detection accuracy with
              the state-of-art approaches validated for significantly larger
              lesions.",
  journal  = "IEEE J Biomed Health Inform",
  volume   =  24,
  number   =  10,
  pages    = "2883--2893",
  month    =  mar,
  year     =  2020,
  address  = "United States",
  language = "en"
}

@ARTICLE{Xue:2020,
  title    = "Deep learning-based detection and segmentation-assisted
              management of brain metastases",
  author   = "Xue, Jie and Wang, Bao and Ming, Yang and Liu, Xuejun and Jiang,
              Zekun and Wang, Chengwei and Liu, Xiyu and Chen, Ligang and Qu,
              Jianhua and Xu, Shangchen and Tang, Xuqun and Mao, Ying and Liu,
              Yingchao and Li, Dengwang",
  abstract = "BACKGROUND: Three-dimensional T1 magnetization prepared rapid
              acquisition gradient echo (3D-T1-MPRAGE) is preferred in
              detecting brain metastases (BM) among MRI. We developed an
              automatic deep learning-based detection and segmentation method
              for BM (named BMDS net) on 3D-T1-MPRAGE images and evaluated its
              performance. METHODS: The BMDS net is a cascaded 3D fully
              convolution network (FCN) to automatically detect and segment BM.
              In total, 1652 patients with 3D-T1-MPRAGE images from 3 hospitals
              (n = 1201, 231, and 220, respectively) were retrospectively
              included. Manual segmentations were obtained by a
              neuroradiologist and a radiation oncologist in a consensus
              reading in 3D-T1-MPRAGE images. Sensitivity, specificity, and
              dice ratio of the segmentation were evaluated. Specificity and
              sensitivity measure the fractions of relevant segmented voxels.
              Dice ratio was used to quantitatively measure the overlap between
              automatic and manual segmentation results. Paired samples t-tests
              and analysis of variance were employed for statistical analysis.
              RESULTS: The BMDS net can detect all BM, providing a detection
              result with an accuracy of 100\%. Automatic segmentations
              correlated strongly with manual segmentations through 4-fold
              cross-validation of the dataset with 1201 patients: the
              sensitivity was 0.96 $\pm$ 0.03 (range, 0.84-0.99), the
              specificity was 0.99 $\pm$ 0.0002 (range, 0.99-1.00), and the
              dice ratio was 0.85 $\pm$ 0.08 (range, 0.62-0.95) for total tumor
              volume. Similar performances on the other 2 datasets also
              demonstrate the robustness of BMDS net in correctly detecting and
              segmenting BM in various settings. CONCLUSIONS: The BMDS net
              yields accurate detection and segmentation of BM automatically
              and could assist stereotactic radiotherapy management for
              diagnosis, therapy planning, and follow-up.",
  journal  = "Neuro Oncol",
  volume   =  22,
  number   =  4,
  pages    = "505--514",
  month    =  apr,
  year     =  2020,
  address  = "England",
  keywords = "MRI; brain metastases; deep learning; fully convolution network;
              stereotactic radiotherapy",
  language = "en"
}

@ARTICLE{Jalalifar:2020,
  title    = "A Cascaded {Deep-Learning} Framework for Segmentation of
              Metastatic Brain Tumors Before and After Stereotactic Radiation
              Therapy()",
  author   = "Jalalifar, Ali and Soliman, Hany and Sahgal, Arjun and
              Sadeghi-Naini, Ali",
  abstract = "Radiation therapy is a major treatment option for brain
              metastasis. For radiation treatment planning and outcome
              evaluation, magnetic resonance (MR) images are acquired before
              and at multiple sessions after the treatment. Accurate
              segmentation of brain tumors on MR images is crucial for
              treatment planning, response evaluation, and developing
              data-driven models for outcome prediction. Due to the high volume
              of imaging data acquired from each patient at multiple follow-up
              sessions, manual tumor segmentation is resource- and
              time-consuming in clinic, hence developing an automatic
              segmentation framework is highly desirable. In this work, we
              proposed a cascaded 2D-3D Unet framework to segment brain tumors
              automatically on contrast-enhanced T1- weighted images acquired
              before and at multiple scan sessions after radiotherapy. 2D Unet
              is a well-known structure for medical image segmentation. 3D Unet
              is an extension of 2D Unet with a volumetric input image to
              provide richer spatial information. The limitation of 3D Unet is
              that it is memory consuming and cannot process large volumetric
              images. To address this limitation, a large volumetric input of
              3D Unet is often patched to smaller volumes which leads to loss
              of context. To overcome this problem, we proposed using two
              cascaded 2D Unets to crop the input volume around the tumor area
              and reduce the input size of the 3D Unet, obviating the need to
              patch the input images. The framework was trained using images
              acquired from 96 patients before radiation therapy and tested
              using images acquired from 10 patients before and at four
              follow-up scans after radiotherapy. The segmentation results for
              the images of independent test set demonstrated that the cascaded
              framework outperformed the 2D and 3D Unets alone, with an average
              Dice score of 0.9 versus 0.86 and 0.88 for the baseline, and 0.87
              versus 0.83 and 0.84 for the first followup. Similar results were
              obtained for the other follow-up scans.",
  journal  = "Annu Int Conf IEEE Eng Med Biol Soc",
  volume   =  2020,
  pages    = "1063--1066",
  month    =  jul,
  year     =  2020,
  address  = "United States",
  language = "en"
}

@ARTICLE{Zhou:2020,
  title    = "{MetNet}: Computer-aided segmentation of brain metastases in
              post-contrast T1-weighted magnetic resonance imaging",
  author   = "Zhou, Zijian and Sanders, Jeremiah W and Johnson, Jason M and
              Gule-Monroe, Maria and Chen, Melissa and Briere, Tina M and Wang,
              Yan and Son, Jong Bum and Pagel, Mark D and Ma, Jingfei and Li,
              Jing",
  abstract = "PURPOSE: Brain metastases are manually contoured during
              stereotactic radiosurgery (SRS) treatment planning, which is
              time-consuming, potentially challenging, and laborious. The
              purpose of this study was to develop and investigate a 2-stage
              deep learning (DL) approach (MetNet) for brain metastasis
              segmentation in pre-treatment magnetic resonance imaging (MRI).
              MATERIALS AND METHODS: We retrospectively analyzed postcontrast
              3D T1-weighted spoiled gradient echo MRIs from 934 patients who
              underwent SRS between August 2009 and August 2018.
              Neuroradiologists manually identified brain metastases in the
              MRIs. The treating radiation oncologist or physicist contoured
              the brain metastases. We constructed a 2-stage DL ensemble
              consisting of detection and segmentation models to segment the
              brain metastases on the MRIs. We evaluated the performance of
              MetNet by computing sensitivity, positive predictive value (PPV),
              and Dice similarity coefficient (DSC) with respect to metastasis
              size, as well as free-response receiver operating
              characteristics. RESULTS: The 934 patients (mean [$\pm$standard
              deviation] age 59 $\pm$ 13 years, 474 women) were randomly split
              into 80\% training and 20\% testing groups (748:186). For
              patients with metastases 1-52 mm (n = 766), 648 (85\%) were
              detected and segmented with a mean segmentation DSC of 81\% $\pm$
              15\%. Patient-averaged sensitivity was 88\% $\pm$ 19\%, PPV was
              58\% $\pm$ 25\%, and DSC was 85\% $\pm$ 13\% with 3 $\pm$ 3 false
              positives (FPs) per patient. When considering only metastases
              $\geq$6 mm, patient-averaged sensitivity was 99\% $\pm$ 5\%, PPV
              was 67\% $\pm$ 28\%, and DSC was 87\% $\pm$ 13\% with 1 $\pm$ 2
              FPs per patient. CONCLUSION: MetNet can segment brain metastases
              across a broad range of metastasis sizes with high sensitivity,
              low FPs, and high segmentation accuracy in postcontrast
              T1-weighted MRI, potentially aiding treatment planning for SRS.",
  journal  = "Radiother Oncol",
  volume   =  153,
  pages    = "189--196",
  month    =  sep,
  year     =  2020,
  address  = "Ireland",
  keywords = "Brain metastasis; Contrast enhanced MRI; Deep learning; MRI;
              Segmentation; Stereotactic radiosurgery",
  language = "en"
}

@ARTICLE{Pennig:2021,
  title    = "Automated Detection and Segmentation of Brain Metastases in
              Malignant Melanoma: Evaluation of a Dedicated Deep Learning Model",
  author   = "Pennig, L and Shahzad, R and Caldeira, L and Lennartz, S and
              Thiele, F and Goertz, L and Zopfs, D and Mei{\ss}ner, A-K and
              F{\"u}rtjes, G and Perkuhn, M and Kabbasch, C and Grau, S and
              Borggrefe, J and Laukamp, K R",
  abstract = "BACKGROUND AND PURPOSE: Malignant melanoma is an aggressive skin
              cancer in which brain metastases are common. Our aim was to
              establish and evaluate a deep learning model for fully automated
              detection and segmentation of brain metastases in patients with
              malignant melanoma using clinical routine MR imaging. MATERIALS
              AND METHODS: Sixty-nine patients with melanoma with a total of
              135 brain metastases at initial diagnosis and available
              multiparametric MR imaging datasets (T1-/T2-weighted, T1-weighted
              gadolinium contrast-enhanced, FLAIR) were included. A previously
              established deep learning model architecture (3D convolutional
              neural network; DeepMedic) simultaneously operating on the
              aforementioned MR images was trained on a cohort of 55 patients
              with 103 metastases using 5-fold cross-validation. The efficacy
              of the deep learning model was evaluated using an independent
              test set consisting of 14 patients with 32 metastases. Manual
              segmentations of metastases in a voxelwise manner (T1-weighted
              gadolinium contrast-enhanced imaging) performed by 2 radiologists
              in consensus served as the ground truth. RESULTS: After training,
              the deep learning model detected 28 of 32 brain metastases (mean
              volume, 1.0 [SD, 2.4] cm(3)) in the test cohort correctly
              (sensitivity of 88\%), while false-positive findings of 0.71 per
              scan were observed. Compared with the ground truth, automated
              segmentations achieved a median Dice similarity coefficient of
              0.75. CONCLUSIONS: Deep learning-based automated detection and
              segmentation of brain metastases in malignant melanoma yields
              high detection and segmentation accuracy with false-positive
              findings of <1 per scan.",
  journal  = "AJNR Am J Neuroradiol",
  volume   =  42,
  number   =  4,
  pages    = "655--662",
  month    =  feb,
  year     =  2021,
  address  = "United States",
  language = "en"
}

@ARTICLE{Jünger:2021,
  title    = "Fully Automated {MR} Detection and Segmentation of Brain
              Metastases in Non-small Cell Lung Cancer Using Deep Learning",
  author   = "J{\"u}nger, Stephanie T and Hoyer, Ulrike Cornelia Isabel and
              Schaufler, Diana and Laukamp, Kai Roman and Goertz, Lukas and
              Thiele, Frank and Grunz, Jan-Peter and Schlamann, Marc and
              Perkuhn, Michael and Kabbasch, Christoph and Persigehl, Thorsten
              and Grau, Stefan and Borggrefe, Jan and Scheffler, Matthias and
              Shahzad, Rahil and Pennig, Lenhard",
  abstract = "BACKGROUND: Non-small cell lung cancer (NSCLC) is the most common
              tumor entity spreading to the brain and up to 50\% of patients
              develop brain metastases (BMs). Detection of BMs on MRI is
              challenging with an inherent risk of missed diagnosis. PURPOSE:
              To train and evaluate a deep learning model (DLM) for fully
              automated detection and 3D segmentation of BMs in NSCLC on
              clinical routine MRI. STUDY TYPE: Retrospective. POPULATION:
              Ninety-eight NSCLC patients with 315 BMs on pretreatment MRI,
              divided into training (66 patients, 248 BMs) and independent test
              (17 patients, 67 BMs) and control (15 patients, 0 BMs) cohorts.
              FIELD STRENGTH/SEQUENCE: T(1) -/T(2) -weighted, T(1) -weighted
              contrast-enhanced (T(1) CE; gradient-echo and spin-echo
              sequences), and FLAIR at 1.0, 1.5, and 3.0 T from various vendors
              and study centers. ASSESSMENT: A 3D convolutional neural network
              (DeepMedic) was trained on the training cohort using 5-fold
              cross-validation and evaluated on the independent test and
              control sets. Three-dimensional voxel-wise manual segmentations
              of BMs by a neurosurgeon and a radiologist on T(1) CE served as
              the reference standard. STATISTICAL TESTS: Sensitivity (recall)
              and false positive (FP) findings per scan, dice similarity
              coefficient (DSC) to compare the spatial overlap between manual
              and automated segmentations, Pearson's correlation coefficient
              (r) to evaluate the relationship between quantitative volumetric
              measurements of segmentations, and Wilcoxon rank-sum test to
              compare the volumes of BMs. A P value <0.05 was considered
              statistically significant. RESULTS: In the test set, the DLM
              detected 57 of the 67 BMs (mean volume: 0.99 $\pm$ 4.24 cm(3) ),
              resulting in a sensitivity of 85.1\%, while FP findings of 1.5
              per scan were observed. Missed BMs had a significantly smaller
              volume (0.05 $\pm$ 0.04 cm(3) ) than detected BMs (0.96 $\pm$ 2.4
              cm(3) ). Compared with the reference standard, automated
              segmentations achieved a median DSC of 0.72 and a good volumetric
              correlation (r = 0.95). In the control set, 1.8 FPs/scan were
              observed. DATA CONCLUSION: Deep learning provided a high
              detection sensitivity and good segmentation performance for BMs
              in NSCLC on heterogeneous scanner data while yielding a low
              number of FP findings. Level of Evidence 3 Technical Efficacy
              Stage 2.",
  journal  = "J Magn Reson Imaging",
  volume   =  54,
  number   =  5,
  pages    = "1608--1622",
  month    =  may,
  year     =  2021,
  address  = "United States",
  keywords = "brain metastases; deep learning; magnetic resonance imaging;
              non-small cell lung cancer",
  language = "en"
}

@Article{Ocaña-Tienda:2023,
author={Oca{\~{n}}a-Tienda, Beatriz
and P{\'e}rez-Beteta, Juli{\'a}n
and Villanueva-Garc{\'i}a, Jos{\'e} D.
and Romero-Rosales, Jos{\'e} A.
and Molina-Garc{\'i}a, David
and Suter, Yannick
and Asenjo, Beatriz
and Albillo, David
and Ortiz de Mendivil, Ana
and P{\'e}rez-Romasanta, Luis A.
and Gonz{\'a}lez-Del Portillo, Elisabet
and Llorente, Manuel
and Carballo, Natalia
and Nagib-Raya, F{\'a}tima
and Vidal-Denis, Maria
and Luque, Bel{\'e}n
and Reyes, Mauricio
and Arana, Estanislao
and P{\'e}rez-Garc{\'i}a, V{\'i}ctor M.},
title={A comprehensive dataset of annotated brain metastasis MR images with clinical and radiomic data},
journal={Scientific Data},
year={2023},
month={Apr},
day={14},
volume={10},
number={1},
pages={208},
abstract={Brain metastasis (BM) is one of the main complications of many cancers, and the most frequent malignancy of the central nervous system. Imaging studies of BMs are routinely used for diagnosis of disease, treatment planning and follow-up. Artificial Intelligence (AI) has great potential to provide automated tools to assist in the management of disease. However, AI methods require large datasets for training and validation, and to date there have been just one publicly available imaging dataset of 156 BMs. This paper publishes 637 high-resolution imaging studies of 75 patients harboring 260 BM lesions, and their respective clinical data. It also includes semi-automatic segmentations of 593 BMs, including pre- and post-treatment T1-weighted cases, and a set of morphological and radiomic features for the cases segmented. This data-sharing initiative is expected to enable research into and performance evaluation of automatic BM detection, lesion segmentation, disease status evaluation and treatment planning methods for BMs, as well as the development and validation of predictive and prognostic tools with clinical applicability.},
issn={2052-4463},
doi={10.1038/s41597-023-02123-0},
url={https://doi.org/10.1038/s41597-023-02123-0}
}

@ARTICLE{Zhang:2019,
  title    = "Noncoplanar {VMAT} for Brain Metastases: A Plan Quality and
              Delivery Efficiency Comparison With Coplanar {VMAT}, {IMRT}, and
              {CyberKnife}",
  author   = "Zhang, Shuming and Yang, Ruijie and Shi, Chengyu and Li, Jiaqi
              and Zhuang, Hongqing and Tian, Suqing and Wang, Junjie",
  abstract = "PURPOSE: To compare plan quality and delivery efficiency of
              noncoplanar volumetric modulated arc therapy with coplanar
              volumetric modulated arc therapy, intensity-modulated radiation
              therapy, and CyberKnife for multiple brain metastases. METHODS:
              For 15 patients with multiple brain metastases, noncoplanar
              volumetric modulated arc therapy, coplanar volumetric modulated
              arc therapy, intensity-modulated radiation therapy, and
              CyberKnife plans with a prescription dose of 30 Gy in 3 fractions
              were generated. Noncoplanar volumetric modulated arc therapy and
              coplanar volumetric modulated arc therapy plans consisted of 4
              noncoplanar arcs and 2 full coplanar arcs, respectively.
              Intensity-modulated radiation therapy plans consisted of 7
              coplanar fields. CyberKnife plans used skull tracking to ensure
              accurate position. All plans were generated to cover 95\% target
              volume with prescription dose. Gradient index, conformity index,
              normal brain tissue volume (V(3Gy) - V(24Gy)), monitor units, and
              beam on time were evaluated. RESULTS: Gradient index was the
              lowest for CyberKnife (3.49 $\pm$ 0.65), followed by noncoplanar
              volumetric modulated arc therapy (4.21 $\pm$ 1.38), coplanar
              volumetric modulated arc therapy (4.87 $\pm$ 1.35), and
              intensity-modulated radiation therapy (5.36 $\pm$ 1.98).
              Conformity index was the largest for noncoplanar volumetric
              modulated arc therapy (0.87 $\pm$ 0.03), followed by coplanar
              volumetric modulated arc therapy (0.86 $\pm$ 0.04), CyberKnife
              (0.86 $\pm$ 0.07), and intensity-modulated radiation therapy
              (0.85 $\pm$ 0.05). Normal brain tissue volume at high-to-moderate
              dose spreads (V(24Gy) - V(9Gy)) was significantly reduced in
              noncoplanar volumetric modulated arc therapy over that of
              intensity-modulated radiation therapy and coplanar volumetric
              modulated arc therapy. Normal brain tissue volume for noncoplanar
              volumetric modulated arc therapy was comparable with noncoplanar
              volumetric modulated arc therapy at high-dose level (V(24Gy) -
              V(15Gy)) and larger than CyberKnife at moderate-to-low dose level
              (V(12Gy) - V(3Gy)). Monitor units was highest for CyberKnife (28
              733.59 $\pm$ 7197.85), followed by intensity-modulated radiation
              therapy (4128.40 $\pm$ 1185.38), noncoplanar volumetric modulated
              arc therapy (3105.20 $\pm$ 371.23), and coplanar volumetric
              modulated arc therapy (2997.27 $\pm$ 446.84). Beam on time was
              longest for CyberKnife (30.25 $\pm$ 7.32 minutes), followed by
              intensity-modulated radiation therapy (2.95 $\pm$ 0.85 minutes),
              noncoplanar volumetric modulated arc therapy (2.61 $\pm$ 0.07
              minutes), and coplanar volumetric modulated arc therapy (2.30
              $\pm$ 0.23 minutes). CONCLUSION: For brain metastases far away
              from organs-at-risk, noncoplanar volumetric modulated arc therapy
              generated more rapid dose falloff and higher conformity compared
              to intensity-modulated radiation therapy and coplanar volumetric
              modulated arc therapy. Noncoplanar volumetric modulated arc
              therapy provided a comparable dose falloff with CyberKnife at
              high-dose level and a slower dose falloff than CyberKnife at
              moderate-to-low dose level. Noncoplanar volumetric modulated arc
              therapy plans had less monitor units and shorter beam on time
              than CyberKnife plans.",
  journal  = "Technol Cancer Res Treat",
  volume   =  18,
  pages    = "1533033819871621",
  month    =  jan,
  year     =  2019,
  address  = "United States",
  keywords = "CyberKnife; IMRT; coplanar VMAT; dosimetry; multiple brain
              metastases; noncoplanar VMAT",
  language = "en"
}

@ARTICLE{Desai:2020,
  title    = "Therapeutic Role of Gamma Knife Stereotactic Radiosurgery in
              {Neuro-Oncology}",
  author   = "Desai, Rupen and Rich, Keith M",
  abstract = "The Gamma Knife Center of St. Louis has established itself as a
              key facility offering stereotactic radiosurgery (SRS) for a
              variety of neuro-oncologic disorders. Since the Gamma Knife unit
              was first brought to Washington University in 1997, we have
              treated 5,696 patients. In this review, we discuss the effective
              role of Gamma Knife SRS in the treatment strategies for patients
              with neuro-oncologic disorders including brain metastases,
              meningiomas, pituitary adenomas, and acoustic neuromas. While
              there is active ongoing research evaluating the most effective
              treatment for patients with these disorders, it is clear that
              best management practices may be tailored for individual patients
              utilizing SRS either alone or in conjunction alternative
              treatment strategies including open neurosurgical procedures,
              laser thermos-ablative surgery, and even new medical oncological
              treatment strategies.",
  journal  = "Mo Med",
  volume   =  117,
  number   =  1,
  pages    = "33--38",
  month    =  jan,
  year     =  2020,
  address  = "United States",
  language = "en"
}

@INCOLLECTION{Arora:2023,
  title     = "Palliative Radiation Therapy For Brain Metastases",
  booktitle = "{StatPearls}",
  author    = "Arora, Rahul D and Agarwal, Mohit S and Maani, Elizabeth V and
               Cascella, Marco",
  abstract  = "Central nervous system (CNS) involvement by tumoral metastasis
               is a potentially life-threatening complication, representing the
               immediate cause of death in more than 50 percent of the cases.
               Of note, brain metastasis represents the most common brain tumor
               in the United States (US). The most common brain metastasizing
               tumors include primaries from the lungs, breast, colon, skin
               (melanoma), and kidney. Two-year and five-year survival rates of
               8.1 percent and 2.4 percent are noted for those with
               intracranial metastasis across various tumor types. Moreover, it
               has been estimated that 10-40 percent of all patients with
               cancer will eventually develop brain metastasis. The lack of
               reporting of the extent of metastatic spread at the time of
               enrolment into studies and follow-up in advanced cancer patients
               (who might go onto develop intracranial metastasis later) might
               be the reason underlying the underdiagnosis of this disease
               entity. The most common spread route is through the hematogenous
               route with the seeding of the brain tissue (microvasculature).
               Interactions between the tumor and the microvascular niche, a
               neuroinflammatory cascade that aids the spread of tumor and
               neovascularization, have been postulated to underlie the primary
               tumor's spread. Intertumoral heterogeneity within the metastatic
               deposits and a failure to fully understand the clonally selected
               molecular aberrations might underlie the consistently poor
               prognosis associated with the tumor's spread to the CNS. The
               brain ecosystem represents a unique microenvironment with the
               inherent ability to aid and limit tumor homing in equal
               measures. While the microvasculature promotes the spread of
               tumors, penetration of systemic therapies to the brain tissue is
               limited. Understanding the various mechanisms predisposing to
               the homing of the tumor cells to the brain and basic knowledge
               of genetic alterations is necessary for planning optimum
               treatment. Radiation therapy aims to mitigate the adverse impact
               of intracranial metastasis on survival and improve the
               health-related quality of life (HRQoL). Recent research in the
               management of brain metastasis has focused upon using targeted
               therapies that have good local bioavailability, strategies to
               provide conformal radiation, limiting adverse effects of
               irradiation on neurocognitive, and outlining relevant
               indications for optimum use of immunotherapy. Local therapy
               choice depends upon various parameters, namely patient factors
               (performance status, stage, and estimated survival), tumor
               factors (location of metastasis, type of tumor, number, size,
               and extracranial disease status), and prior treatment history.
               The first evidence of the utility of whole-brain radiotherapy
               (WBRT) in palliation of brain metastasis came from Chao et al.
               Their paper was also significant for reporting a high incidence
               of recurrence in irradiated patients. Subsequent studies by
               Borgelt et al. were designed to explore the equivalence between
               different dose fractionation regimens. Both a dose fractionation
               schedule of 30 Gray in 10 fractions and 37.5 Gray in 15
               fractions were equally effective. This chapter aims to recall,
               analyze, and select appropriate indications and
               contraindications for the use of palliative radiotherapy in
               patients with intracranial metastasis. The clinical
               significance, technique involved, and recent advances in
               providing palliative radiotherapy in this clinical setting are
               also addressed.",
  publisher = "StatPearls Publishing",
  month     =  jan,
  year      =  2023,
  address   = "Treasure Island (FL)",
  language  = "en"
}

@ARTICLE{Park:2021,
  title    = "Robust performance of deep learning for automatic detection and
              segmentation of brain metastases using three-dimensional
              black-blood and three-dimensional gradient echo imaging",
  author   = "Park, Yae Won and Jun, Yohan and Lee, Yangho and Han, Kyunghwa
              and An, Chansik and Ahn, Sung Soo and Hwang, Dosik and Lee,
              Seung-Koo",
  abstract = "OBJECTIVES: To evaluate whether a deep learning (DL) model using
              both three-dimensional (3D) black-blood (BB) imaging and 3D
              gradient echo (GRE) imaging may improve the detection and
              segmentation performance of brain metastases compared to that
              using only 3D GRE imaging. METHODS: A total of 188 patients with
              brain metastases (917 lesions) who underwent a brain metastasis
              MRI protocol including contrast-enhanced 3D BB and 3D GRE were
              included in the training set. DL models based on 3D U-net were
              constructed. The models were validated in the test set consisting
              of 45 patients with brain metastases (203 lesions) and 49
              patients without brain metastases. RESULTS: The combined 3D BB
              and 3D GRE model yielded better performance than the 3D GRE model
              (sensitivities of 93.1\% vs 76.8\%, p < 0.001), and this effect
              was significantly stronger in subgroups with small metastases (p
              interaction < 0.001). For metastases < 3 mm, $\geq$ 3 mm and < 10
              mm, and $\geq$ 10 mm, the sensitivities were 82.4\%, 93.2\%, and
              100\%, respectively. The combined 3D BB and 3D GRE model showed a
              false-positive per case of 0.59 in the test set. The combined 3D
              BB and 3D GRE model showed a Dice coefficient of 0.822, while 3D
              GRE model showed a lower Dice coefficient of 0.756. CONCLUSIONS:
              The combined 3D BB and 3D GRE DL model may improve the detection
              and segmentation performance of brain metastases, especially in
              detecting small metastases. KEY POINTS: • The combined 3D BB and
              3D GRE model yielded better performance for the detection of
              brain metastases than the 3D GRE model (p < 0.001), with
              sensitivities of 93.1\% and 76.8\%, respectively. • The combined
              3D BB and 3D GRE model showed a false-positive rate per case of
              0.59 in the test set. • The combined 3D BB and 3D GRE model
              showed a Dice coefficient of 0.822, while the 3D GRE model showed
              a lower Dice coefficient of 0.756.",
  journal  = "Eur Radiol",
  volume   =  31,
  number   =  9,
  pages    = "6686--6695",
  month    =  mar,
  year     =  2021,
  address  = "Germany",
  keywords = "Artificial intelligence; Deep learning; Magnetic resonance
              imaging; Neoplasm metastasis",
  language = "en"
}

@book{Chollet:2017,
  added-at = {2018-08-01T08:16:18.000+0200},
  author = {Chollet, François},
  biburl = {https://www.bibsonomy.org/bibtex/231f94815ebbd65d3a31e4a69e818573e/jaeschke},
  interhash = {cfbfd3f93853a469e5e6978f61a74a0a},
  intrahash = {31f94815ebbd65d3a31e4a69e818573e},
  isbn = {9781617294433},
  keywords = {ai deep deeplearning learning ml},
  month = nov,
  publisher = {Manning},
  timestamp = {2021-05-19T08:35:34.000+0200},
  title = {Deep Learning with Python },
  year = 2017
}

@article{Kingma:2014,
  added-at = {2023-03-05T10:30:55.000+0100},
  author = {Kingma, Diederik P and Ba, Jimmy},
  biburl = {https://www.bibsonomy.org/bibtex/28bdee324b737a54ae326ea6db6e8950b/jascal_panetzky},
  interhash = {57d2ac873f398f21bb94790081e80394},
  intrahash = {8bdee324b737a54ae326ea6db6e8950b},
  journal = {arXiv preprint arXiv:1412.6980},
  keywords = {imported},
  timestamp = {2023-03-05T10:34:04.000+0100},
  title = {Adam: A method for stochastic optimization},
  year = 2014
}

@article{Kamnitsas:2017,
title = {Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation},
journal = {Medical Image Analysis},
volume = {36},
pages = {61-78},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516301839},
author = {Konstantinos Kamnitsas and Christian Ledig and Virginia F.J. Newcombe and Joanna P. Simpson and Andrew D. Kane and David K. Menon and Daniel Rueckert and Ben Glocker},
keywords = {3D convolutional neural network, Fully connected CRF, Segmentation, Brain lesions, Deep learning},
abstract = {We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have devised an efficient and effective dense training scheme which joins the processing of adjacent image patches into one pass through the network while automatically adapting to the inherent class imbalance present in the data. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network’s soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumours, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient, which allows its adoption in a variety of research and clinical settings. The source code of our implementation is made publicly available.}
}

@INPROCEEDINGS{Sun:2019,
  author={Sun, Ke and Xiao, Bin and Liu, Dong and Wang, Jingdong},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep High-Resolution Representation Learning for Human Pose Estimation}, 
  year={2019},
  volume={},
  number={},
  pages={5686-5696},
  doi={10.1109/CVPR.2019.00584}}

@ARTICLE{Badrinarayanan:2017,
  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}, 
  year={2017},
  volume={39},
  number={12},
  pages={2481-2495},
  doi={10.1109/TPAMI.2016.2644615}}

@article{Kumar:2018,
  author       = {Pulkit Kumar and
                  Pravin Nagar and
                  Chetan Arora and
                  Anubha Gupta},
  title        = {U-SegNet: Fully Convolutional Neural Network based Automated Brain
                  tissue segmentation Tool},
  journal      = {CoRR},
  volume       = {abs/1806.04429},
  year         = {2018},
  url          = {http://arxiv.org/abs/1806.04429},
  eprinttype    = {arXiv},
  eprint       = {1806.04429},
  timestamp    = {Mon, 13 Aug 2018 16:48:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1806-04429.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Ballangrud:2018,
  title    = "Institutional experience with {SRS} {VMAT} planning for multiple
              cranial metastases",
  author   = "Ballangrud, {\AA}se and Kuo, Li Cheng and Happersett, Laura and
              Lim, Seng Boh and Beal, Kathryn and Yamada, Yoshiya and Hunt,
              Margie and Mechalakos, James",
  abstract = "BACKGROUND AND PURPOSE: This study summarizes the cranial
              stereotactic radiosurgery (SRS) volumetric modulated arc therapy
              (VMAT) procedure at our institution. MATERIALS AND METHODS:
              Volumetric modulated arc therapy plans were generated for 40
              patients with 188 lesions (range 2-8, median 5) in Eclipse and
              treated on a TrueBeam STx. Limitations of the custom beam model
              outside the central 2.5 mm leaves necessitated more than one
              isocenter pending the spatial distribution of lesions. Two to
              nine arcs were used per isocenter. Conformity index (CI),
              gradient index (GI) and target dose heterogeneity index (HI) were
              determined for each lesion. Dose to critical structures and
              treatment times are reported. RESULTS: Lesion size ranged
              0.05-17.74 cm(3) (median 0.77 cm(3) ), and total tumor volume per
              case ranged 1.09-26.95 cm(3) (median 7.11 cm(3) ). For each
              lesion, HI ranged 1.2-1.5 (median 1.3), CI ranged 1.0-2.9 (median
              1.2), and GI ranged 2.5-8.4 (median 4.4). By correlating GI to
              PTV volume a predicted GI = 4/PTV(0.2) was determined and
              implemented in a script in Eclipse and used for plan evaluation.
              Brain volume receiving 7 Gy (V(7 Gy) ) ranged 10-136 cm(3)
              (median 42 cm(3) ). Total treatment time ranged 24-138 min
              (median 61 min). CONCLUSIONS: Volumetric modulated arc therapy
              provide plans with steep dose gradients around the targets and
              low dose to critical structures, and VMAT treatment is delivered
              in a shorter time than conventional methods using one isocenter
              per lesion. To further improve VMAT planning for multiple cranial
              metastases, better tools to shorten planning time are needed. The
              most significant improvement would come from better dose modeling
              in Eclipse, possibly by allowing for customizing the dynamic leaf
              gap (DLG) for a special SRS model and not limit to one DLG per
              energy per treatment machine and thereby remove the limitation on
              the Y-jaw and allow planning with a single isocenter.",
  journal  = "J Appl Clin Med Phys",
  volume   =  19,
  number   =  2,
  pages    = "176--183",
  month    =  feb,
  year     =  2018,
  address  = "United States",
  keywords = "SRS; VMAT; cranial metastases",
  language = "en"
}

@ARTICLE{Yoo:2021,
  title    = "Evaluating deep learning methods in detecting and segmenting
              different sizes of brain metastases on {3D} post-contrast
              T1-weighted images",
  author   = "Yoo, Youngjin and Ceccaldi, Pascal and Liu, Siqi and Re, Thomas J
              and Cao, Yue and Balter, James M and Gibson, Eli",
  abstract = "Purpose: We investigate the impact of various deep-learning-based
              methods for detecting and segmenting metastases with different
              lesion volume sizes on 3D brain MR images. Approach: A 2.5D U-Net
              and a 3D U-Net were selected. We also evaluated weak learner
              fusion of the prediction features generated by the 2.5D and the
              3D networks. A 3D fully convolutional one-stage (FCOS) detector
              was selected as a representative of bounding-box regression-based
              detection methods. A total of 422 3D post-contrast T1-weighted
              scans from patients with brain metastases were used. Performances
              were analyzed based on lesion volume, total metastatic volume per
              patient, and number of lesions per patient. Results: The
              performance of detection of the 2.5D and 3D U-Net methods had
              recall of > 0.83 and precision of > 0.44 for lesion volume > 0.3
              cm3 but deteriorated as metastasis size decreased below 0.3 cm3
              to 0.58 to 0.74 in recall and 0.16 to 0.25 in precision. Compared
              the two U-Nets for detection capability, high precision was
              achieved by the 2.5D network, but high recall was achieved by the
              3D network for all lesion sizes. The weak learner fusion achieved
              a balanced performance between the 2.5D and 3D U-Nets;
              particularly, it increased precision to 0.83 for lesion volumes
              of 0.1 to 0.3 cm3 but decreased recall to 0.59. The 3D FCOS
              detector did not outperform the U-Net methods in detecting either
              the small or large metastases presumably because of the limited
              data size. Conclusions: Our study provides the performances of
              four deep learning methods in relationship to lesion size, total
              metastasis volume, and number of lesions per patient, providing
              insight into further development of the deep learning networks.",
  journal  = "J Med Imaging (Bellingham)",
  volume   =  8,
  number   =  3,
  pages    = "037001",
  month    =  may,
  year     =  2021,
  address  = "United States",
  keywords = "brain metastasis; deep learning; detection; magnetic resonance
              imaging; magnetization-prepared rapid gradient echo;
              segmentation; small lesion",
  language = "en"
}


@Article{Grøvik:2021,
author={Gr{\o}vik, Endre
and Yi, Darvin
and Iv, Michael
and Tong, Elizabeth
and Nilsen, Line Brennhaug
and Latysheva, Anna
and Saxhaug, Cathrine
and Jacobsen, Kari Dolven
and Helland, {\AA}slaug
and Emblem, Kyrre Eeg
and Rubin, Daniel L.
and Zaharchuk, Greg},
title={Handling missing MRI sequences in deep learning segmentation of brain metastases: a multicenter study},
journal={npj Digital Medicine},
year={2021},
month={Feb},
day={22},
volume={4},
number={1},
pages={33},
abstract={The purpose of this study was to assess the clinical value of a deep learning (DL) model for automatic detection and segmentation of brain metastases, in which a neural network is trained on four distinct MRI sequences using an input-level dropout layer, thus simulating the scenario of missing MRI sequences by training on the full set and all possible subsets of the input data. This retrospective, multicenter study, evaluated 165 patients with brain metastases. The proposed input-level dropout (ILD) model was trained on multisequence MRI from 100 patients and validated/tested on 10/55 patients, in which the test set was missing one of the four MRI sequences used for training. The segmentation results were compared with the performance of a state-of-the-art DeepLab V3 model. The MR sequences in the training set included pre-gadolinium and post-gadolinium (Gd) T1-weighted 3D fast spin echo, post-Gd T1-weighted inversion recovery (IR) prepped fast spoiled gradient echo, and 3D fluid attenuated inversion recovery (FLAIR), whereas the test set did not include the IR prepped image-series. The ground truth segmentations were established by experienced neuroradiologists. The results were evaluated using precision, recall, Intersection over union (IoU)-score and Dice score, and receiver operating characteristics (ROC) curve statistics, while the Wilcoxon rank sum test was used to compare the performance of the two neural networks. The area under the ROC curve (AUC), averaged across all test cases, was 0.989{\thinspace}{\textpm}{\thinspace}0.029 for the ILD-model and 0.989{\thinspace}{\textpm}{\thinspace}0.023 for the DeepLab V3 model (p{\thinspace}={\thinspace}0.62). The ILD-model showed a significantly higher Dice score (0.795{\thinspace}{\textpm}{\thinspace}0.104 vs. 0.774{\thinspace}{\textpm}{\thinspace}0.104, p{\thinspace}={\thinspace}0.017), and IoU-score (0.561{\thinspace}{\textpm}{\thinspace}0.225 vs. 0.492{\thinspace}{\textpm}{\thinspace}0.186, p{\thinspace}<{\thinspace}0.001) compared to the DeepLab V3 model, and a significantly lower average false positive rate of 3.6/patient vs. 7.0/patient (p{\thinspace}<{\thinspace}0.001) using a 10 mm3 lesion-size limit. The ILD-model, trained on all possible combinations of four MRI sequences, may facilitate accurate detection and segmentation of brain metastases on a multicenter basis, even when the test cohort is missing input MRI sequences.},
issn={2398-6352},
doi={10.1038/s41746-021-00398-4},
url={https://doi.org/10.1038/s41746-021-00398-4}
}

@ARTICLE{Hsu:2021,
  title    = "Automatic segmentation of brain metastases using {T1} magnetic
              resonance and computed tomography images",
  author   = "Hsu, Dylan G and Ballangrud, {\AA}se and Shamseddine, Achraf and
              Deasy, Joseph O and Veeraraghavan, Harini and Cervino, Laura and
              Beal, Kathryn and Aristophanous, Michalis",
  abstract = "An increasing number of patients with multiple brain metastases
              are being treated with stereotactic radiosurgery (SRS). Manually
              identifying and contouring all metastatic lesions is difficult
              and time-consuming, and a potential source of variability. Hence,
              we developed a 3D deep learning approach for segmenting brain
              metastases on MR and CT images. Five-hundred eleven patients
              treated with SRS were retrospectively identified for this study.
              Prior to radiotherapy, the patients were imaged with 3D T1
              spoiled-gradient MR post-Gd (T1 + C) and contrast-enhanced CT
              (CECT), which were co-registered by a treatment planner. The
              gross tumor volume contours, authored by the attending radiation
              oncologist, were taken as the ground truth. There were 3 $\pm$ 4
              metastases per patient, with volume up to 57 ml. We produced a
              multi-stage model that automatically performs brain extraction,
              followed by detection and segmentation of brain metastases using
              co-registered T1 + C and CECT. Augmented data from 80\% of these
              patients were used to train modified 3D V-Net convolutional
              neural networks for this task. We combined a normalized boundary
              loss function with soft Dice loss to improve the model
              optimization, and employed gradient accumulation to stabilize the
              training. The average Dice similarity coefficient (DSC) for brain
              extraction was 0.975 $\pm$ 0.002 (95\% CI). The detection
              sensitivity per metastasis was 90\% (329/367), with moderate
              dependence on metastasis size. Averaged across 102 test patients,
              our approach had metastasis detection sensitivity 95 $\pm$ 3\%,
              2.4 $\pm$ 0.5 false positives, DSC of 0.76 $\pm$ 0.03, and
              95th-percentile Hausdorff distance of 2.5 $\pm$ 0.3 mm (95\%
              CIs). The volumes of automatic and manual segmentations were
              strongly correlated for metastases of volume up to 20 ml
              (r=0.97,p<0.001). This work expounds a fully 3D deep learning
              approach capable of automatically detecting and segmenting brain
              metastases using co-registered T1 + C and CECT.",
  journal  = "Phys Med Biol",
  volume   =  66,
  number   =  17,
  month    =  aug,
  year     =  2021,
  address  = "England",
  keywords = "CECT; MRI; boundary loss; brain metastases; convolutional neural
              network; deep learning; skull stripping",
  language = "en"
}

@ARTICLE{Cho:2021,
  
AUTHOR={Cho, Jungheum and Kim, Young Jae and Sunwoo, Leonard and Lee, Gi Pyo and Nguyen, Toan Quang and Cho, Se Jin and Baik, Sung Hyun and Bae, Yun Jung and Choi, Byung Se and Jung, Cheolkyu and Sohn, Chul-Ho and Han, Jung-Ho and Kim, Chae-Yong and Kim, Kwang Gi and Kim, Jae Hyoung},   
	 
TITLE={Deep Learning-Based Computer-Aided Detection System for Automated Treatment Response Assessment of Brain Metastases on 3D MRI},      
	
JOURNAL={Frontiers in Oncology},      
	
VOLUME={11},           
	
YEAR={2021},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fonc.2021.739639},       
	
DOI={10.3389/fonc.2021.739639},      
	
ISSN={2234-943X},   
   
ABSTRACT={<sec>BackgroundAlthough accurate treatment response assessment for brain metastases (BMs) is crucial, it is highly labor intensive. This retrospective study aimed to develop a computer-aided detection (CAD) system for automated BM detection and treatment response evaluation using deep learning.</sec><sec>MethodsWe included 214 consecutive MRI examinations of 147 patients with BM obtained between January 2015 and August 2016. These were divided into the training (174 MR images from 127 patients) and test datasets according to temporal separation (temporal test set #1; 40 MR images from 20 patients). For external validation, 24 patients with BM and 11 patients without BM from other institutions were included (geographic test set). In addition, we included 12 MRIs from BM patients obtained between August 2017 and March 2020 (temporal test set #2). Detection sensitivity, dice similarity coefficient (DSC) for segmentation, and agreements in one-dimensional and volumetric Response Assessment in Neuro-Oncology Brain Metastases (RANO-BM) criteria between CAD and radiologists were assessed.</sec><sec>ResultsIn the temporal test set #1, the sensitivity was 75.1\% (95\% confidence interval [CI]: 69.6\%, 79.9\%), mean DSC was 0.69 ± 0.22, and false-positive (FP) rate per scan was 0.8 for BM ≥ 5 mm. Agreements in the RANO-BM criteria were moderate (κ, 0.52) and substantial (κ, 0.68) for one-dimensional and volumetric, respectively. In the geographic test set, sensitivity was 87.7\% (95\% CI: 77.2\%, 94.5\%), mean DSC was 0.68 ± 0.20, and FP rate per scan was 1.9 for BM ≥ 5 mm. In the temporal test set #2, sensitivity was 94.7\% (95\% CI: 74.0\%, 99.9\%), mean DSC was 0.82 ± 0.20, and FP per scan was 0.5 (6/12) for BM ≥ 5 mm.</sec><sec>ConclusionsOur CAD showed potential for automated treatment response assessment of BM ≥ 5 mm.</sec>}
}

@ARTICLE{Sun:2021,
  title    = "Can {3D} artificial intelligence models outshine {2D} ones in the
              detection of intracranial metastatic tumors on magnetic resonance
              images?",
  author   = "Sun, Ying-Chou and Hsieh, Ang-Ting and Fang, Ssu-Ting and Wu,
              Hsiu-Mei and Kao, Liang-Wei and Chung, Wen-Yuh and Chen,
              Hung-Hsun and Liou, Kang-Du and Lin, Yu-Shiou and Guo, Wan-Yuo
              and Lu, Henry Horng-Shing",
  abstract = "BACKGROUND: This study aimed to compare the prediction
              performance of two-dimensional (2D) and three-dimensional (3D)
              semantic segmentation models for intracranial metastatic tumors
              with a volume $\geq$ 0.3 mL. METHODS: We used postcontrast T1
              whole-brain magnetic resonance (MR), which was collected from
              Taipei Veterans General Hospital (TVGH). Also, the study was
              approved by the institutional review board (IRB) of TVGH. The 2D
              image segmentation model does not fully use the spatial
              information between neighboring slices, whereas the 3D
              segmentation model does. We treated the U-Net as the basic model
              for 2D and 3D architectures. RESULTS: For the prediction of
              intracranial metastatic tumors, the area under the curve (AUC) of
              the 3D model was 87.6\% and that of the 2D model was 81.5\%.
              CONCLUSION: Building a semantic segmentation model based on 3D
              deep convolutional neural networks might be crucial to achieve a
              high detection rate in clinical applications for intracranial
              metastatic tumors.",
  journal  = "J Chin Med Assoc",
  volume   =  84,
  number   =  10,
  pages    = "956--962",
  month    =  oct,
  year     =  2021,
  address  = "Netherlands",
  language = "en"
}

@ARTICLE{Huang:2022,
  title    = "Deep learning for brain metastasis detection and segmentation in
              longitudinal {MRI} data",
  author   = "Huang, Yixing and Bert, Christoph and Sommer, Philipp and Frey,
              Benjamin and Gaipl, Udo and Distel, Luitpold V and Weissmann,
              Thomas and Uder, Michael and Schmidt, Manuel A and D{\"o}rfler,
              Arnd and Maier, Andreas and Fietkau, Rainer and Putz, Florian",
  abstract = "PURPOSE: Brain metastases (BM) occur frequently in patients with
              metastatic cancer. Early and accurate detection of BM is
              essential for treatment planning and prognosis in radiation
              therapy. Due to their tiny sizes and relatively low contrast,
              small BM are very difficult to detect manually. With the recent
              development of deep learning technologies, several res earchers
              have reported promising results in automated brain metastasis
              detection. However, the detection sensitivity is still not high
              enough for tiny BM, and integration into clinical practice in
              regard to differentiating true metastases from false positives
              (FPs) is challenging. METHODS: The DeepMedic network with the
              binary cross-entropy (BCE) loss is used as our baseline method.
              To improve brain metastasis detection performance, a custom
              detection loss called volume-level sensitivity-specificity (VSS)
              is proposed, which rates metastasis detection sensitivity and
              specificity at a (sub)volume level. As sensitivity and precision
              are always a trade-off, either a high sensitivity or a high
              precision can be achieved for brain metastasis detection by
              adjusting the weights in the VSS loss without decline in dice
              score coefficient for segmented metastases. To reduce
              metastasis-like structures being detected as FP metastases, a
              temporal prior volume is proposed as an additional input of
              DeepMedic. The modified network is called DeepMedic+ for
              distinction. Combining a high-sensitivity VSS loss and a high
              specificity loss for DeepMedic+, the majority of true positive
              metastases are confirmed with high specificity, while additional
              metastases candidates in each patient are marked with high
              sensitivity for detailed expert evaluation. RESULTS: Our proposed
              VSS loss improves the sensitivity of brain metastasis detection,
              increasing the sensitivity from 85.3\% for DeepMedic with BCE to
              97.5\% for DeepMedic with VSS. Alternatively, the precision is
              improved from 69.1\% for DeepMedic with BCE to 98.7\% for
              DeepMedic with VSS. Comparing DeepMedic+ with DeepMedic with the
              same VSS loss, 44.4\% of the FP metastases are reduced in the
              high-sensitivity model and the precision reaches 99.6\% for the
              high-specificity model. The mean dice coefficient for all
              metastases is about 0.81. With the ensemble of the
              high-sensitivity and high-specificity models, on average only 1.5
              FP metastases per patient need further check, while the majority
              of true positive metastases are confirmed. CONCLUSIONS: Our
              proposed VSS loss and temporal prior improve brain metastasis
              detection sensitivity and precision. The ensemble learning is
              able to distinguish high confidence true positive metastases from
              metastases candidates that require special expert review or
              further follow-up, being particularly well-fit to the
              requirements of expert support in real clinical practice. This
              facilitates metastasis detection and segmentation for
              neuroradiologists in diagnostic and radiation oncologists in
              therapeutic clinical applications.",
  journal  = "Med Phys",
  volume   =  49,
  number   =  9,
  pages    = "5773--5786",
  month    =  jul,
  year     =  2022,
  address  = "United States",
  keywords = "MRI; brain metastasis; deep learning; ensemble; loss function;
              sensitivity specificity",
  language = "en"
}

@ARTICLE{Yoo:2022,
  title    = "{Deep-Learning-Based} Automatic Detection and Segmentation of
              Brain Metastases with Small Volume for Stereotactic Ablative
              Radiotherapy",
  author   = "Yoo, Sang Kyun and Kim, Tae Hyung and Chun, Jaehee and Choi,
              Byong Su and Kim, Hojin and Yang, Sejung and Yoon, Hong In and
              Kim, Jin Sung",
  abstract = "Recently, several efforts have been made to develop the deep
              learning (DL) algorithms for automatic detection and segmentation
              of brain metastases (BM). In this study, we developed an advanced
              DL model to BM detection and segmentation, especially for
              small-volume BM. From the institutional cancer registry,
              contrast-enhanced magnetic resonance images of 65 patients and
              603 BM were collected to train and evaluate our DL model. Of the
              65 patients, 12 patients with 58 BM were assigned to test-set for
              performance evaluation. Ground-truth for BM was assigned to one
              radiation oncologist to manually delineate BM and another one to
              cross-check. Unlike other previous studies, our study dealt with
              relatively small BM, so the area occupied by the BM in the
              high-resolution images were small. Our study applied training
              techniques such as the overlapping patch technique and
              2.5-dimensional (2.5D) training to the well-known U-Net
              architecture to learn better in smaller BM. As a DL architecture,
              2D U-Net was utilized by 2.5D training. For better efficacy and
              accuracy of a two-dimensional U-Net, we applied effective
              preprocessing include 2.5D overlapping patch technique. The
              sensitivity and average false positive rate were measured as
              detection performance, and their values were 97\% and 1.25 per
              patient, respectively. The dice coefficient with dilation and
              95\% Hausdorff distance were measured as segmentation
              performance, and their values were 75\% and 2.057 mm,
              respectively. Our DL model can detect and segment BM with small
              volume with good performance. Our model provides considerable
              benefit for clinicians with automatic detection and segmentation
              of BM for stereotactic ablative radiotherapy.",
  journal  = "Cancers (Basel)",
  volume   =  14,
  number   =  10,
  month    =  may,
  year     =  2022,
  address  = "Switzerland",
  keywords = "autosegmentation; brain metastases; convolutional neural network;
              deep learning; magnetic resonance imaging; stereotactic ablative
              radiotherapy",
  language = "en"
}

@ARTICLE{Bouget:2022,
  title    = "Preoperative Brain Tumor Imaging: Models and Software for
              Segmentation and Standardized Reporting",
  author   = "Bouget, David and Pedersen, Andr{\'e} and Jakola, Asgeir S and
              Kavouridis, Vasileios and Emblem, Kyrre E and Eijgelaar, Roelant
              S and Kommers, Ivar and Ardon, Hilko and Barkhof, Frederik and
              Bello, Lorenzo and Berger, Mitchel S and Conti Nibali, Marco and
              Furtner, Julia and Hervey-Jumper, Shawn and Idema, Albert J S and
              Kiesel, Barbara and Kloet, Alfred and Mandonnet, Emmanuel and
              M{\"u}ller, Domenique M J and Robe, Pierre A and Rossi, Marco and
              Sciortino, Tommaso and Van den Brink, Wimar A and Wagemakers,
              Michiel and Widhalm, Georg and Witte, Marnix G and Zwinderman,
              Aeilko H and De Witt Hamer, Philip C and Solheim, Ole and
              Reinertsen, Ingerid",
  abstract = "For patients suffering from brain tumor, prognosis estimation and
              treatment decisions are made by a multidisciplinary team based on
              a set of preoperative MR scans. Currently, the lack of
              standardized and automatic methods for tumor detection and
              generation of clinical reports, incorporating a wide range of
              tumor characteristics, represents a major hurdle. In this study,
              we investigate the most occurring brain tumor types:
              glioblastomas, lower grade gliomas, meningiomas, and metastases,
              through four cohorts of up to 4,000 patients. Tumor segmentation
              models were trained using the AGU-Net architecture with different
              preprocessing steps and protocols. Segmentation performances were
              assessed in-depth using a wide-range of voxel and patient-wise
              metrics covering volume, distance, and probabilistic aspects.
              Finally, two software solutions have been developed, enabling an
              easy use of the trained models and standardized generation of
              clinical reports: Raidionics and Raidionics-Slicer. Segmentation
              performances were quite homogeneous across the four different
              brain tumor types, with an average true positive Dice ranging
              between 80 and 90\%, patient-wise recall between 88 and 98\%, and
              patient-wise precision around 95\%. In conjunction to Dice, the
              identified most relevant other metrics were the relative absolute
              volume difference, the variation of information, and the
              Hausdorff, Mahalanobis, and object average symmetric surface
              distances. With our Raidionics software, running on a desktop
              computer with CPU support, tumor segmentation can be performed in
              16-54 s depending on the dimensions of the MRI volume. For the
              generation of a standardized clinical report, including the tumor
              segmentation and features computation, 5-15 min are necessary.
              All trained models have been made open-access together with the
              source code for both software solutions and validation metrics
              computation. In the future, a method to convert results from a
              set of metrics into a final single score would be highly
              desirable for easier ranking across trained models. In addition,
              an automatic classification of the brain tumor type would be
              necessary to replace manual user input. Finally, the inclusion of
              post-operative segmentation in both software solutions will be
              key for generating complete post-operative standardized clinical
              reports.",
  journal  = "Front Neurol",
  volume   =  13,
  pages    = "932219",
  month    =  jul,
  year     =  2022,
  address  = "Switzerland",
  keywords = "3D segmentation; MRI; RADS; deep learning; glioma; meningioma;
              metastasis; open-source software",
  language = "en"
}

@ARTICLE{Liang:2022,
  title    = "Deep {Learning-Based} Automatic Detection of Brain Metastases in
              Heterogenous {Multi-Institutional} Magnetic Resonance Imaging
              Sets: An Exploratory Analysis of {NRG-CC001}",
  author   = "Liang, Ying and Lee, Karen and Bovi, Joseph A and Palmer, Joshua
              D and Brown, Paul D and Gondi, Vinai and Tom{\'e}, Wolfgang A and
              Benzinger, Tammie L S and Mehta, Minesh P and Li, X Allen",
  abstract = "PURPOSE: Deep learning-based algorithms have been shown to be
              able to automatically detect and segment brain metastases (BMs)
              in magnetic resonance imaging, mostly based on
              single-institutional data sets. This work aimed to investigate
              the use of deep convolutional neural networks (DCNN) for BM
              detection and segmentation on a highly heterogeneous
              multi-institutional data set. METHODS AND MATERIALS: A total of
              407 patients from 98 institutions were randomly split into 326
              patients from 78 institutions for training/validation and 81
              patients from 20 institutions for unbiased testing. The data set
              contained T1-weighted gadolinium and T2-weighted fluid-attenuated
              inversion recovery magnetic resonance imaging acquired on diverse
              scanners using different pulse sequences and various acquisition
              parameters. Several variants of 3-dimensional U-Net based DCNN
              models were trained and tuned using 5-fold cross validation on
              the training set. Performances of different models were compared
              based on Dice similarity coefficient for segmentation and
              sensitivity and false positive rate (FPR) for detection. The best
              performing model was evaluated on the test set. RESULTS: A DCNN
              with an input size of 64 $\times$ 64 $\times$ 64 and an equal
              number of 128 kernels for all convolutional layers using instance
              normalization was identified as the best performing model (Dice
              similarity coefficient 0.73, sensitivity 0.86, and FPR 1.9) in
              the 5-fold cross validation experiments. The best performing
              model demonstrated consistent behavior on the test set (Dice
              similarity coefficient 0.73, sensitivity 0.91, and FPR 1.7) and
              successfully detected 7 BMs (out of 327) that were missed during
              manual delineation. For large BMs with diameters greater than 12
              mm, the sensitivity and FPR improved to 0.98 and 0.3,
              respectively. CONCLUSIONS: The DCNN model developed can
              automatically detect and segment brain metastases with reasonable
              accuracy, high sensitivity, and low FPR on a multi-institutional
              data set with nonprespecified and highly variable magnetic
              resonance imaging sequences. For large BMs, the model achieved
              clinically relevant results. The model is robust and may be
              potentially used in real-world situations.",
  journal  = "Int J Radiat Oncol Biol Phys",
  volume   =  114,
  number   =  3,
  pages    = "529--536",
  month    =  jul,
  year     =  2022,
  address  = "United States",
  language = "en"
}

@ARTICLE{Lyu:2022,
  title    = "A transformer-based deep-learning approach for classifying brain
              metastases into primary organ sites using clinical whole-brain
              {MRI} images",
  author   = "Lyu, Qing and Namjoshi, Sanjeev V and McTyre, Emory and
              Topaloglu, Umit and Barcus, Richard and Chan, Michael D and
              Cramer, Christina K and Debinski, Waldemar and Gurcan, Metin N
              and Lesser, Glenn J and Lin, Hui-Kuan and Munden, Reginald F and
              Pasche, Boris C and Sai, Kiran K S and Strowd, Roy E and Tatter,
              Stephen B and Watabe, Kounosuke and Zhang, Wei and Wang, Ge and
              Whitlow, Christopher T",
  abstract = "Treatment decisions for brain metastatic disease rely on
              knowledge of the primary organ site and are currently made with
              biopsy and histology. Here, we develop a deep-learning approach
              for accurate non-invasive digital histology with whole-brain
              magnetic resonance imaging (MRI) data. Contrast-enhanced
              T1-weighted and fast spoiled gradient echo brain MRI exams (n =
              1,582) were preprocessed and input to the proposed deep-learning
              workflow for tumor segmentation, modality transfer, and primary
              site classification into one of five classes. Tenfold
              cross-validation generated an overall area under the receiver
              operating characteristic curve (AUC) of 0.878 (95\% confidence
              interval [CI]: 0.873,0.883). These data establish that
              whole-brain imaging features are discriminative enough to allow
              accurate diagnosis of the primary organ site of malignancy. Our
              end-to-end deep radiomic approach has great potential for
              classifying metastatic tumor types from whole-brain MRI images.
              Further refinement may offer an invaluable clinical tool to
              expedite primary cancer site identification for precision
              treatment and improved outcomes.",
  journal  = "Patterns (N Y)",
  volume   =  3,
  number   =  11,
  pages    = "100613",
  month    =  oct,
  year     =  2022,
  address  = "United States",
  keywords = "MRI; brain metastasis; classification; deep learning; primary
              organ site; vision transformer",
  language = "en"
}

@ARTICLE{Liew:2022,
  title    = "Gradual {Self-Training} via Confidence and Volume Based Domain
              Adaptation for Multi Dataset Deep {Learning-Based} Brain
              Metastases Detection Using Nonlocal Networks on {MRI} Images",
  author   = "Liew, Andrea and Lee, Chun Cheng and Subramaniam, Valarmathy and
              Lan, Boon Leong and Tan, Maxine",
  abstract = "BACKGROUND: Research suggests that treatment of multiple brain
              metastases (BMs) with stereotactic radiosurgery shows improvement
              when metastases are detected early, providing a case for BM
              detection capabilities on small lesions. PURPOSE: To demonstrate
              automatic detection of BM on three MRI datasets using a deep
              learning-based approach. To improve the performance of the
              network is iteratively co-trained with datasets from different
              domains. A systematic approach is proposed to prevent
              catastrophic forgetting during co-training. STUDY TYPE:
              Retrospective. POPULATION: A total of 156 patients (105 ground
              truth and 51 pseudo labels) with 1502 BM (BrainMetShare); 121
              patients with 722 BM (local); 400 patients with 447 primary
              gliomas (BrATS). Training/pseudo labels/validation data were
              distributed 84/51/21 (BrainMetShare). Training/validation data
              were split: 121/23 (local) and 375/25 (BrATS). FIELD
              STRENGTH/SEQUENCE: A 5 T and 3 T/T1 spin-echo postcontrast
              (T1-gradient echo) (BrainMetShare), 3 T/T1 magnetization prepared
              rapid acquisition gradient echo postcontrast (T1-MPRAGE) (local),
              0.5 T, 1 T, and 1.16 T/T1-weighted-fluid-attenuated inversion
              recovery (T1-FLAIR) (BrATS). ASSESSMENT: The ground truth was
              manually segmented by two (BrainMetShare) and four (BrATS)
              radiologists and manually annotated by one (local) radiologist.
              Confidence and volume based domain adaptation (CAVEAT) method of
              co-training the three datasets on a 3D nonlocal convolutional
              neural network (CNN) architecture was implemented to detect BM.
              STATISTICAL TESTS: The performance was evaluated using
              sensitivity and false positive rates per patient (FP/patient) and
              free receiver operating characteristic (FROC) analysis at seven
              predefined (1/8, 1/4, 1/2, 1, 2, 4, and 8) FPs per scan. RESULTS:
              The sensitivity and FP/patient from a held-out set registered
              0.811 at 2.952 FP/patient (BrainMetShare), 0.74 at 3.130 (local),
              and 0.723 at 2.240 (BrATS) using the CAVEAT approach with lesions
              as small as 1 mm being detected. DATA CONCLUSION: Improved
              sensitivities at lower FP can be achieved by co-training datasets
              via the CAVEAT paradigm to address the problem of data sparsity.
              LEVEL OF EVIDENCE: 3 TECHNICAL EFFICACY STAGE: 2.",
  journal  = "J Magn Reson Imaging",
  month    =  oct,
  year     =  2022,
  address  = "United States",
  keywords = "BM detection; BRATS; BrainMetShare; domain adaptation; nonlocal
              networks; self-training",
  language = "en"
}

@ARTICLE{Chartrand:2022,
  title    = "Automated Detection of Brain Metastases on {T1-Weighted} {MRI}
              Using a Convolutional Neural Network: Impact of Volume Aware Loss
              and Sampling Strategy",
  author   = "Chartrand, Gabriel and Emiliani, Ram{\'o}n D and Pawlowski,
              Sophie A and Markel, Daniel A and Bahig, Houda and
              Cengarle-Samak, Alexandre and Rajakesari, Selvan and Lavoie,
              Jeremi and Ducharme, Simon and Roberge, David",
  abstract = "BACKGROUND: Detection of brain metastases (BM) and segmentation
              for treatment planning could be optimized with machine learning
              methods. Convolutional neural networks (CNNs) are promising, but
              their trade-offs between sensitivity and precision frequently
              lead to missing small lesions. HYPOTHESIS: Combining volume aware
              (VA) loss function and sampling strategy could improve BM
              detection sensitivity. STUDY TYPE: Retrospective. POPULATION: A
              total of 530 radiation oncology patients (55\% women) were split
              into a training/validation set (433 patients/1460 BM) and an
              independent test set (97 patients/296 BM). FIELD
              STRENGTH/SEQUENCE: 1.5 T and 3 T, contrast-enhanced
              three-dimensional (3D) T1-weighted fast gradient echo sequences.
              ASSESSMENT: Ground truth masks were based on radiotherapy
              treatment planning contours reviewed by experts. A U-Net inspired
              model was trained. Three loss functions (Dice, Dice + boundary,
              and VA) and two sampling methods (label and VA) were compared.
              Results were reported with Dice scores, volumetric error, lesion
              detection sensitivity, and precision. A detected voxel within the
              ground truth constituted a true positive. STATISTICAL TESTS:
              McNemar's exact test to compare detected lesions between models.
              Pearson's correlation coefficient and Bland-Altman analysis to
              compare volume agreement between predicted and ground truth
              volumes. Statistical significance was set at P $\leq$ 0.05.
              RESULTS: Combining VA loss and VA sampling performed best with an
              overall sensitivity of 91\% and precision of 81\%. For BM in the
              2.5-6 mm estimated sphere diameter range, VA loss reduced false
              negatives by 58\% and VA sampling reduced it further by 30\%. In
              the same range, the boundary loss achieved the highest precision
              at 81\%, but a low sensitivity (24\%) and a 31\% Dice loss. DATA
              CONCLUSION: Considering BM size in the loss and sampling function
              of CNN may increase the detection sensitivity regarding small BM.
              Our pipeline relying on a single contrast-enhanced T1-weighted
              MRI sequence could reach a detection sensitivity of 91\%, with an
              average of only 0.66 false positives per scan. EVIDENCE LEVEL: 3
              TECHNICAL EFFICACY: Stage 2.",
  journal  = "J Magn Reson Imaging",
  volume   =  56,
  number   =  6,
  pages    = "1885--1898",
  month    =  may,
  year     =  2022,
  address  = "United States",
  keywords = "brain metastases; deep learning; detection; loss function;
              radiotherapy; segmentation",
  language = "en"
}

@Article{Jalalifar:2022,
AUTHOR = {Jalalifar, Seyed Ali and Soliman, Hany and Sahgal, Arjun and Sadeghi-Naini, Ali},
TITLE = {Impact of Tumour Segmentation Accuracy on Efficacy of Quantitative MRI Biomarkers of Radiotherapy Outcome in Brain Metastasis},
JOURNAL = {Cancers},
VOLUME = {14},
YEAR = {2022},
NUMBER = {20},
ARTICLE-NUMBER = {5133},
URL = {https://www.mdpi.com/2072-6694/14/20/5133},
PubMedID = {36291917},
ISSN = {2072-6694},
ABSTRACT = {Significantly affecting patients&rsquo; clinical course and quality of life, a growing number of cancer cases are diagnosed with brain metastasis (BM) annually. Stereotactic radiotherapy is now a major treatment option for patients with BM. However, it may take months before the local response of BM to stereotactic radiation treatment is apparent on standard follow-up imaging. While machine learning in conjunction with radiomics has shown great promise in predicting the local response of BM before or early after radiotherapy, further development and widespread application of such techniques has been hindered by their dependency on manual tumour delineation. In this study, we explored the impact of using less-accurate automatically generated segmentation masks on the efficacy of radiomic features for radiotherapy outcome prediction in BM. The findings of this study demonstrate that while the effect of tumour delineation accuracy is substantial for segmentation models with lower dice scores (dice score &le; 0.85), radiomic features and prediction models are rather resilient to imperfections in the produced tumour masks. Specifically, the selected radiomic features (six shared features out of seven) and performance of the prediction model (accuracy of 80\% versus 80\%, AUC of 0.81 versus 0.78) were fairly similar for the ground-truth and automatically generated segmentation masks, with dice scores close to 0.90. The positive outcome of this work paves the way for adopting high-throughput automatically generated tumour masks for discovering diagnostic and prognostic imaging biomarkers in BM without sacrificing accuracy.},
DOI = {10.3390/cancers14205133}
}

@ARTICLE{Lee:2022,
  title    = "Lesion delineation framework for vestibular schwannoma,
              meningioma and brain metastasis for gamma knife radiosurgery
              using stereotactic magnetic resonance images",
  author   = "Lee, Wei-Kai and Yang, Huai-Che and Lee, Cheng-Chia and Lu,
              Chia-Feng and Wu, Chih-Chun and Chung, Wen-Yuh and Wu, Hsiu-Mei
              and Guo, Wan-Yuo and Wu, Yu-Te",
  abstract = "BACKGROUND AND OBJECTIVE: GKRS is an effective treatment for
              smaller intracranial tumors with a high control rate and low risk
              of complications. Target delineation in medical MR images is
              essential in the planning of GKRS and follow-up. A deep
              learning-based algorithm can effectively segment the targets from
              medical images and has been widely explored. However,
              state-of-the-art deep learning-based target delineation uses
              fixed sizes, and the isotropic voxel size may not be suitable for
              stereotactic MR images which use different anisotropic voxel
              sizes and numbers of slices according to the lesion size and
              location for clinical GKRS planning. This study developed an
              automatic deep learning-based segmentation scheme for
              stereotactic MR images. METHODS: We retrospectively collected
              stereotactic MR images from 506 patients with VS, 1,069 patients
              with meningioma and 574 patients with BM who had been treated
              using GKRS; the lesion contours and individual T1W+C and T2W MR
              images were extracted from the GammaPlan system. The
              three-dimensional patching-based training strategy and
              dual-pathway architecture were used to manage inconsistent FOVs
              and anisotropic voxel size. Furthermore, we used two-parametric
              MR image as training input to segment the regions with different
              image characteristics (e.g., cystic lesions) effectively.
              RESULTS: Our results for VS and BM demonstrated that the model
              trained using two-parametric MR images significantly outperformed
              the model trained using single-parametric images with median Dice
              coefficients (0.91, 0.05 versus 0.90, 0.06, and 0.82, 0.23 versus
              0.78, 0.34, respectively), whereas predicted delineations in
              meningiomas using the dual-pathway model were dominated by
              single-parametric images (median Dice coefficients 0.83, 0.17
              versus 0.84, 0.22). Finally, we combined three data sets to train
              the models, achieving the comparable or even higher testing
              median Dice (VS: 0.91, 0.07; meningioma: 0.83, 0.22; BM: 0.84,
              0.23) in three diseases while using two-parametric as input.
              CONCLUSIONS: Our proposed deep learning-based tumor segmentation
              scheme was successfully applied to multiple types of intracranial
              tumor (VS, meningioma and BM) undergoing GKRS and for segmenting
              the tumor effectively from stereotactic MR image volumes for use
              in GKRS planning.",
  journal  = "Comput Methods Programs Biomed",
  volume   =  229,
  pages    = "107311",
  month    =  dec,
  year     =  2022,
  address  = "Ireland",
  keywords = "Convolutional neural network; Gamma knife; Magnetic resonance
              imaging; Radiosurgery",
  language = "en"
}

@ARTICLE{Li:2023,
  title    = "{MRI-based} two-stage deep learning model for automatic detection
              and segmentation of brain metastases",
  author   = "Li, Ruikun and Guo, Yujie and Zhao, Zhongchen and Chen, Mingming
              and Liu, Xiaoqing and Gong, Guanzhong and Wang, Lisheng",
  abstract = "OBJECTIVES: To develop and validate a two-stage deep learning
              model for automatic detection and segmentation of brain
              metastases (BMs) in MRI images. METHODS: In this retrospective
              study, T1-weighted (T1) and T1-weighted contrast-enhanced (T1ce)
              MRI images of 649 patients who underwent radiotherapy from August
              2019 to January 2022 were included. A total of 5163 metastases
              were manually annotated by neuroradiologists. A two-stage deep
              learning model was developed for automatic detection and
              segmentation of BMs, which consisted of a lightweight
              segmentation network for generating metastases proposals and a
              multi-scale classification network for false-positive
              suppression. Its performance was evaluated by sensitivity,
              precision, F1-score, dice, and relative volume difference (RVD).
              RESULTS: Six hundred forty-nine patients were randomly divided
              into training (n = 295), validation (n = 99), and testing (n =
              255) sets. The proposed two-stage model achieved a sensitivity of
              90\% (1463/1632) and a precision of 56\% (1463/2629) on the
              testing set, outperforming one-stage methods based on a
              single-shot detector, 3D U-Net, and nnU-Net, whose sensitivities
              were 78\% (1276/1632), 79\% (1290/1632), and 87\% (1426/1632),
              and the precisions were 40\% (1276/3222), 51\% (1290/2507), and
              53\% (1426/2688), respectively. Particularly for BMs smaller than
              5 mm, the proposed model achieved a sensitivity of 66\%
              (116/177), far superior to one-stage models (21\% (37/177), 36\%
              (64/177), and 53\% (93/177)). Furthermore, it also achieved high
              segmentation performance with an average dice of 81\% and an
              average RVD of 20\%. CONCLUSION: A two-stage deep learning model
              can detect and segment BMs with high sensitivity and low volume
              error. KEY POINTS: • A two-stage deep learning model based on
              triple-channel MRI images identified brain metastases with 90\%
              sensitivity and 56\% precision. • For brain metastases smaller
              than 5 mm, the proposed two-stage model achieved 66\% sensitivity
              and 22\% precision. • For segmentation of brain metastases, the
              proposed two-stage model achieved a dice of 81\% and a relative
              volume difference (RVD) of 20\%.",
  journal  = "Eur Radiol",
  volume   =  33,
  number   =  5,
  pages    = "3521--3531",
  month    =  jan,
  year     =  2023,
  address  = "Germany",
  keywords = "Brain metastases; Deep learning; Magnetic resonance imaging",
  language = "en"
}

@ARTICLE{Jalalifar:2023,
  title    = "Automatic Assessment of Stereotactic Radiation Therapy Outcome in
              Brain Metastasis using Longitudinal Segmentation on Serial {MRI}",
  author   = "Jalalifar, Seyed Ali and Soliman, Hany and Sahgal, Arjun and
              Sadeghi-Naini, Ali",
  abstract = "The standard clinical approach to assess the radiotherapy outcome
              in brain metastasis is through monitoring the changes in tumour
              size on longitudinal MRI. This assessment requires contouring the
              tumour on many volumetric images acquired before and at several
              follow-up scans after the treatment that is routinely done
              manually by oncologists with a substantial burden on the clinical
              workflow. In this work, we introduce a novel system for automatic
              assessment of stereotactic radiation therapy (SRT) outcome in
              brain metastasis using standard serial MRI. At the heart of the
              proposed system is a deep learning-based segmentation framework
              to delineate tumours longitudinally on serial MRI with high
              precision. Longitudinal changes in tumour size are then analyzed
              automatically to assess the local response and detect possible
              adverse radiation effects (ARE) after SRT. The system was trained
              and optimized using the data acquired from 96 patients (130
              tumours) and evaluated on an independent test set of 20 patients
              (22 tumours; 95 MRI scans). The comparison between automatic
              therapy outcome evaluation and manual assessments by expert
              oncologists demonstrates a good agreement with an accuracy,
              sensitivity, and specificity of 91\%, 89\%, and 92\%,
              respectively, in detecting local control/failure and 91\%, 100\%,
              and 89\% in detecting ARE on the independent test set. This study
              is a step forward towards automatic monitoring and evaluation of
              radiotherapy outcome in brain tumours that can streamline the
              radio-oncology workflow substantially.",
  journal  = "IEEE J Biomed Health Inform",
  volume   = "PP",
  month    =  jan,
  year     =  2023,
  address  = "United States",
  language = "en"
}

@ARTICLE{Yi:2021,
  title    = "{MRI} pulse sequence integration for deep-learning-based brain
              metastases segmentation",
  author   = "Yi, Darvin and Gr{\o}vik, Endre and Tong, Elizabeth and Iv,
              Michael and Emblem, Kyrre Eeg and Nilsen, Line Brennhaug and
              Saxhaug, Cathrine and Latysheva, Anna and Jacobsen, Kari Dolven
              and Helland, {\AA}slaug and Zaharchuk, Greg and Rubin, Daniel",
  abstract = "PURPOSE: Magnetic resonance (MR) imaging is an essential
              diagnostic tool in clinical medicine. Recently, a variety of
              deep-learning methods have been applied to segmentation tasks in
              medical images, with promising results for computer-aided
              diagnosis. For MR images, effectively integrating different pulse
              sequences is important to optimize performance. However, the best
              way to integrate different pulse sequences remains unclear. In
              addition, networks trained with a certain subset of pulse
              sequences as input are unable to perform when given a subset of
              those pulse sequences. In this study, we evaluate multiple
              architectural features and characterize their effects in the task
              of metastasis segmentation while creating a method to robustly
              train a network to be able to work given any strict subset of the
              pulse sequences available during training. METHODS: We use a 2.5D
              DeepLabv3 segmentation network to segment metastases lesions on
              brain MR's with four pulse sequence inputs. To study how we can
              best integrate MR pulse sequences for this task, we consider (1)
              different pulse sequence integration schemas, combining our
              features at early, middle, and late points within a deep network,
              (2) different modes of weight sharing for parallel network
              branches, and (3) a novel integration level dropout layer, which
              will allow the networks to be robust to performing inference on
              input with only a subset of pulse sequences available at the
              training. RESULTS: We find that levels of integration and modes
              of weight sharing that favor low variance work best in our regime
              of small amounts of training data (n = 100). By adding an
              input-level dropout layer, we could preserve the overall
              performance of these networks while allowing for inference on
              inputs with missing pulse sequences. We illustrate not only the
              generalizability of the network but also the utility of this
              robustness when applying the trained model to data from a
              different center, which does not use the same pulse sequences.
              Finally, we apply network visualization methods to better
              understand which input features are most important for network
              performance. CONCLUSIONS: Together, these results provide a
              framework for building networks with enhanced robustness to
              missing data while maintaining comparable performance in medical
              imaging applications.",
  journal  = "Med Phys",
  volume   =  48,
  number   =  10,
  pages    = "6020--6035",
  month    =  aug,
  year     =  2021,
  address  = "United States",
  keywords = "MRI; brain metastases; deep learning segmentation",
  language = "en"
}


@Article{Sarvamangala:2022,
author={Sarvamangala, D. R.
and Kulkarni, Raghavendra V.},
title={Convolutional neural networks in medical image understanding: a survey},
journal={Evolutionary Intelligence},
year={2022},
month={Mar},
day={01},
volume={15},
number={1},
pages={1-22},
abstract={Imaging techniques are used to capture anomalies of the human body. The captured images must be understood for diagnosis, prognosis and treatment planning of the anomalies. Medical image understanding is generally performed by skilled medical professionals. However, the scarce availability of human experts and the fatigue and rough estimate procedures involved with them limit the effectiveness of image understanding performed by skilled medical professionals. Convolutional neural networks (CNNs) are effective tools for image understanding. They have outperformed human experts in many image understanding tasks. This article aims to provide a comprehensive survey of applications of CNNs in medical image understanding. The underlying objective is to motivate medical image understanding researchers to extensively apply CNNs in their research and diagnosis. A brief introduction to CNNs has been presented. A discussion on CNN and its various award-winning frameworks have been presented. The major medical image understanding tasks, namely image classification, segmentation, localization and detection have been introduced. Applications of CNN in medical image understanding of the ailments of brain, breast, lung and other organs have been surveyed critically and comprehensively. A critical discussion on some of the challenges is also presented.},
issn={1864-5917},
doi={10.1007/s12065-020-00540-3},
url={https://doi.org/10.1007/s12065-020-00540-3}
}

@ARTICLE{Okuda:1999,
  title    = "Brain lesions: when should fluid-attenuated inversion-recovery
              sequences be used in {MR} evaluation?",
  author   = "Okuda, T and Korogi, Y and Shigematsu, Y and Sugahara, T and
              Hirai, T and Ikushima, I and Liang, L and Takahashi, M",
  abstract = "PURPOSE: To compare qualitatively and quantitatively the contrast
              of brain lesions detected with fluid-attenuated
              inversion-recovery (FLAIR) and intermediate-weighted sequences at
              magnetic resonance (MR) imaging. MATERIALS AND METHODS: In this
              prospective study, 47 patients suspected of having a brain lesion
              underwent MR imaging with FLAIR, intermediate-weighted, and
              T2-weighted sequences. Qualitative assessment was performed of
              lesion conspicuity, detection, overall image artifact, and
              additional clinical information. Contrast and contrast-to-noise
              ratio (CNR) were calculated between lesions and the normal brain
              or cerebrospinal fluid (CSF). RESULTS: FLAIR images were equal to
              intermediate-weighted images for overall lesion conspicuity and
              detection but were associated more often with image artifacts.
              Lesion-to-background contrast was significantly higher on FLAIR
              than on intermediate-weighted images. FLAIR images failed to
              demonstrate multiple sclerosis (MS) plaques located in the basal
              ganglia and brain stem. CONCLUSION: Although FLAIR images
              provided additional information in some cases, they did not have
              distinct advantages over intermediate-weighted images. When cases
              of MS are evaluated, intermediate-weighted images are preferable
              to FLAIR images. Except in cases of MS, either FLAIR or
              intermediate-weighted sequences should be added to T2-weighted
              sequences at MR imaging.",
  journal  = "Radiology",
  volume   =  212,
  number   =  3,
  pages    = "793--798",
  month    =  sep,
  year     =  1999,
  address  = "United States",
  language = "en"
}

@ARTICLE{Bangerter:2006,
  title    = "Fluid-attenuated inversion-recovery {SSFP} imaging",
  author   = "Bangerter, Neal K and Hargreaves, Brian A and Gold, Garry E and
              Stucker, Daniel T and Nishimura, Dwight G",
  abstract = "PURPOSE: To describe and evaluate a fast, fluid-suppressed 2D
              multislice steady-state free precession (SSFP) neuroimaging
              sequence. MATERIALS AND METHODS: We developed a fast
              fluid-attenuated inversion-recovery SSFP sequence for use in
              neuroimaging. The inversion time (TI) was optimized to yield good
              cerebrospinal fluid (CSF) suppression while conserving white
              matter (WM)/lesion contrast across a broad range of flip angles.
              Multiple SSFP acquisitions were combined using the sum-of-squares
              (SOS) method to maximize SNR efficiency while minimizing SSFP
              banding artifacts. We compared our fluid-attenuated
              inversion-recovery (FLAIR) SSFP sequence with FLAIR fast
              spin-echo (FSE) in both normal subjects and a volunteer with
              multiple sclerosis. SNR measurements were performed to ascertain
              the SNR efficiency of each sequence. RESULTS: Our FLAIR SSFP
              sequence demonstrated excellent CSF suppression and good gray
              matter (GM)/WM contrast. Coverage of the entire brain (5-mm
              slices, 24-cm FOV, 256 x 192 matrix) was achieved with FLAIR SSFP
              in less than half the scan time of a corresponding FLAIR FSE
              sequence with similar SNR, yielding improvements of more than
              50\% in SNR efficiency. Axial scans of a volunteer with multiple
              sclerosis show clearly visible plaques and very good
              visualization of brain parenchyma. CONCLUSION: We have
              demonstrated the feasibility of a very fast fluid-suppressed
              neuroimaging technique using SSFP.",
  journal  = "J Magn Reson Imaging",
  volume   =  24,
  number   =  6,
  pages    = "1426--1431",
  month    =  dec,
  year     =  2006,
  address  = "United States",
  language = "en"
}

@Article{Garcia-Ruiz:2021,
author={Garcia-Ruiz, Alonso
and Naval-Baudin, Pablo
and Ligero, Marta
and Pons-Escoda, Albert
and Bruna, Jordi
and Plans, Gerard
and Calvo, Nahum
and Cos, Monica
and Maj{\'o}s, Carles
and Perez-Lopez, Raquel},
title={Precise enhancement quantification in post-operative MRI as an indicator of residual tumor impact is associated with survival in patients with glioblastoma},
journal={Scientific Reports},
year={2021},
month={Jan},
day={12},
volume={11},
number={1},
pages={695},
abstract={Glioblastoma is the most common primary brain tumor. Standard therapy consists of maximum safe resection combined with adjuvant radiochemotherapy followed by chemotherapy with temozolomide, however prognosis is extremely poor. Assessment of the residual tumor after surgery and patient stratification into prognostic groups (i.e., by tumor volume) is currently hindered by the subjective evaluation of residual enhancement in medical images (magnetic resonance imaging [MRI]). Furthermore, objective evidence defining the optimal time to acquire the images is lacking. We analyzed 144 patients with glioblastoma, objectively quantified the enhancing residual tumor through computational image analysis and assessed the correlation with survival. Pathological enhancement thickness on post-surgical MRI correlated with survival (hazard ratio: 1.98, p{\thinspace}<{\thinspace}0.001). The prognostic value of several imaging and clinical variables was analyzed individually and combined (radiomics AUC 0.71, p{\thinspace}={\thinspace}0.07; combined AUC 0.72, p{\thinspace}<{\thinspace}0.001). Residual enhancement thickness and radiomics complemented clinical data for prognosis stratification in patients with glioblastoma. Significant results were only obtained for scans performed between 24 and 72 h after surgery, raising the possibility of confounding non-tumor enhancement in very early post-surgery MRI. Regarding the extent of resection, and in agreement with recent studies, the association between the measured tumor remnant and survival supports maximal safe resection whenever possible.},
issn={2045-2322},
doi={10.1038/s41598-020-79829-3},
url={https://doi.org/10.1038/s41598-020-79829-3}
}


@ARTICLE{Kinoshita:2005,
  title    = "Curvilinear {T1} hyperintense lesions representing cortical
              necrosis after cerebral infarction",
  author   = "Kinoshita, Toshibumi and Ogawa, Toshihide and Yoshida, Yasuji and
              Tamura, Hajime and Kado, Hirotsugu and Okudera, Toshio",
  abstract = "Curvilinear T1 hyperintense lesions in the cerebral cortex in
              patients with subacute infarction were investigated for: (1) the
              presence or absence of T2* hypointensity and (2) correlations
              with neuropathologic findings. Thirty-six consecutive patients
              with subacute to chronic embolic infarction, in whom curvilinear
              hyperintense lesions in the infarcted cortex were seen on
              T1-weighted images, underwent echo-planar gradient-echo (GRE-EPI)
              T2*-weighted imaging. GRE-EPI T2*-weighted imaging revealed no
              evidence of hemorrhage within the curvilinear T1 hyperintense
              lesions of the cerebral cortex in all of the patients. In 11 of
              the 36 patients, focal hypointense lesions were seen in the depth
              of infarcted gyri on GRE-EPI T2*-weighted images. In the
              remaining 25 patients, no T2* hypointensities were seen in the
              infarct zone. Pathological correlation was performed in a patient
              with middle cerebral artery infarction and curvilinear
              hyperintense lesions on postmortem T1-weighted images. In the
              autopsied brain, curvilinear T1 hyperintense lesions corresponded
              to necrosis of all the cortical layers on histological
              examination. These data suggest that curvilinear hyperintense
              lesions in the cerebral cortex on T1-weighted images during the
              subacute to chronic period of cerebral infarction may not
              represent hemorrhage.",
  journal  = "Neuroradiology",
  volume   =  47,
  number   =  9,
  pages    = "647--651",
  month    =  jul,
  year     =  2005,
  address  = "Germany",
  language = "en"
}

@article{Mazzola:2015, title={Ressonância magnética: princípios de formação da imagem e aplicações em imagem funcional}, volume={3}, url={https://www.rbfm.org.br/rbfm/article/view/51}, DOI={10.29384/rbfm.2009.v3.n1.p117-129}, abstractNote={&amp;lt;p&amp;gt;A imagem por ressonância magnética é hoje um método de diagnóstico estabelecido na prática clínica e em crescente desenvolvimento. A RM funcional se destaca como uma das técnicas que vem permitindo explorar funções cerebrais como a memória, linguagem e controle da motricidade. Esta revisão tem por objetivo explorar de forma introdutória e simplificada a física da imagem por ressonância magnética e demonstrar os mecanismos e aplicações da RM funcional.&amp;lt;/p&amp;gt;}, number={1}, journal={Revista Brasileira de Física Médica}, author={Mazzola, Alessandro A.}, year={2015}, month={out.}, pages={117–129} }

@ARTICLE{Zakaria:2014,
  title    = "The role of magnetic resonance imaging in the management of brain
              metastases: diagnosis to prognosis",
  author   = "Zakaria, Rasheed and Das, Kumar and Bhojak, Maneesh and Radon,
              Mark and Walker, Carol and Jenkinson, Michael D",
  abstract = "This article reviews the different MRI techniques available for
              the diagnosis, treatment and monitoring of brain metastases with
              a focus on applying advanced MR techniques to practical clinical
              problems. Topics include conventional MRI sequences and contrast
              agents, functional MR imaging, diffusion weighted MR, MR
              spectroscopy and perfusion MR. The role of radiographic
              biomarkers is discussed as well as future directions such as
              molecular imaging and MR guided high frequency ultrasound.",
  journal  = "Cancer Imaging",
  volume   =  14,
  number   =  1,
  pages    = "8",
  month    =  apr,
  year     =  2014,
  address  = "England",
  language = "en"
}

@Article{Yousef:2014,
author={Yousef, Ahmed Farid
and Elkharbotly, Amany
and Settin, Magdy
and Mousa, Yasser},
title={Role of diffusion-weighted MR imaging in discrimination between the intracranial cystic masses},
journal={The Egyptian Journal of Radiology and Nuclear Medicine},
year={2014},
month={Sep},
day={01},
volume={45},
number={3},
pages={869-875},
keywords={Diffusion; Brain; Abscess; Tumor},
abstract={Objective Discriminating pyogenic brain abscesses from cystic or necrotic tumors is sometimes difficult with CT or conventional MR imaging. Diffusion MR imaging is a valuable diagnostic test in cases of intracranial cystic masses. Methods This work was conducted from July 2008 to June 2013 on 90 patients; 43 males and 47 females. Their ages range from 5 to 70years. All patients were subjected to routine MRI examination and diffusion weighted imaging using 1.5T MRI scanner. Gadolinium was given to some cases on routine MRI. Diffusion weighted imaging was performed with a single-shot spin-echo echo-planar pulse sequence (b=0--1000s/mm2). The apparent diffusion coefficient values and ratio were measured. Results and conclusions Patients in this study were categorized into three main groups; first group is brain abscesses (36 cases), 91.6{\%} of them showed restricted diffusion, second group is malignant cystic or necrotic brain tumors, 28 cases of high grade necrotic glioma, 60.7{\%} of them are free diffusion, and third group is benign cystic masses, arachnoid and epidermiod cysts (11 cases); all arachnoid cysts are free diffusion. From these results diffusion-weighted imaging is playing an important role in discrimination of cystic intracranial masses.},
issn={0378-603X},
url={https://www.sciencedirect.com/science/article/pii/S0378603X14000734}
}

@ARTICLE{Mehrabian:2019,
AUTHOR={Mehrabian, Hatef and Detsky, Jay and Soliman, Hany and Sahgal, Arjun and Stanisz, Greg J.},   
	 
TITLE={Advanced Magnetic Resonance Imaging Techniques in Management of Brain Metastases},      
	
JOURNAL={Frontiers in Oncology},      
	
VOLUME={9},           
	
YEAR={2019},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fonc.2019.00440},       
	
DOI={10.3389/fonc.2019.00440},      
	
ISSN={2234-943X},   
   
ABSTRACT={Brain metastases are the most common intracranial tumors and occur in 20–40\% of all cancer patients. Lung cancer, breast cancer, and melanoma are the most frequent primary cancers to develop brain metastases. Treatment options include surgical resection, whole brain radiotherapy, stereotactic radiosurgery, and systemic treatment such as targeted or immune therapy. Anatomical magnetic resonance imaging (MRI) of the tumor (in particular post-Gadolinium T<sub>1</sub>-weighted and T<sub>2</sub>-weighted FLAIR) provide information about lesion morphology and structure, and are routinely used in clinical practice for both detection and treatment response evaluation for brain metastases. Advanced MRI biomarkers that characterize the cellular, biophysical, micro-structural and metabolic features of tumors have the potential to improve the management of brain metastases from early detection and diagnosis, to evaluating treatment response. Magnetic resonance spectroscopy (MRS), chemical exchange saturation transfer (CEST), quantitative magnetization transfer (qMT), diffusion-based tissue microstructure imaging, trans-membrane water exchange mapping, and magnetic susceptibility weighted imaging (SWI) are advanced MRI techniques that will be reviewed in this article as they pertain to brain metastases.}
}

@Article{Schneider:2017,
author={Schneider, Tanja
and Kuhne, Jan Felix
and Bittrich, Paul
and Schroeder, Julian
and Magnus, Tim
and Mohme, Malte
and Grosser, Malte
and Schoen, Gerhard
and Fiehler, Jens
and Siemonsen, Susanne},
title={Edema is not a reliable diagnostic sign to exclude small brain metastases},
journal={PLOS ONE},
year={2017},
month={May},
day={11},
publisher={Public Library of Science},
volume={12},
number={5},
pages={e0177217},
abstract={No prior systematic study on the extent of vasogenic edema (VE) in patients with brain metastases (BM) exists. Here, we aim to determine 1) the general volumetric relationship between BM and VE, 2) a threshold diameter above which a BM shows VE, and 3) the influence of the primary tumor and location of the BM in order to improve diagnostic processes and understanding of edema formation. This single center, retrospective study includes 173 untreated patients with histologically proven BM. Semi-manual segmentation of 1416 BM on contrast-enhanced T1-weighted images and of 865 VE on fluid-attenuated inversion recovery/T2-weighted images was conducted. Statistical analyses were performed using a paired-samples t-test, linear regression/generalized mixed-effects model, and receiver-operating characteristic (ROC) curve controlling for the possible effect of non-uniformly distributed metastases among patients. For BM with non-confluent edema (n = 545), there was a statistically significant positive correlation between the volumes of the BM and the VE (P < 0.001). The optimal threshold for edema formation was a diameter of 9.4 mm for all BM. The primary tumors as interaction term in multivariate analysis had a significant influence on VE formation whereas location had not. Hence VE development is dependent on the volume of the underlying BM and the site of the primary neoplasm, but not from the location of the BM.},
doi={10.1371/journal.pone.0177217},
url={https://doi.org/10.1371/journal.pone.0177217}
}

@ARTICLE{Fink:2013,
  title    = "Imaging of brain metastases",
  author   = "Fink, Kathleen R and Fink, James R",
  abstract = "Imaging plays a key role in the diagnosis of central nervous
              system (CNS) metastasis. Imaging is used to detect metastases in
              patients with known malignancies and new neurological signs or
              symptoms, as well as to screen for CNS involvement in patients
              with known cancer. Computed tomography (CT) and magnetic
              resonance imaging (MRI) are the key imaging modalities used in
              the diagnosis of brain metastases. In difficult cases, such as
              newly diagnosed solitary enhancing brain lesions in patients
              without known malignancy, advanced imaging techniques including
              proton magnetic resonance spectroscopy (MRS), contrast enhanced
              magnetic resonance perfusion (MRP), diffusion weighted imaging
              (DWI), and diffusion tensor imaging (DTI) may aid in arriving at
              the correct diagnosis. This image-rich review discusses the
              imaging evaluation of patients with suspected intracranial
              involvement and malignancy, describes typical imaging findings of
              parenchymal brain metastasis on CT and MRI, and provides clues to
              specific histological diagnoses such as the presence of
              hemorrhage. Additionally, the role of advanced imaging techniques
              is reviewed, specifically in the context of differentiating
              metastasis from high-grade glioma and other solitary enhancing
              brain lesions. Extra-axial CNS involvement by metastases,
              including pachymeningeal and leptomeningeal metastases is also
              briefly reviewed.",
  journal  = "Surg Neurol Int",
  volume   =  4,
  number   = "Suppl 4",
  pages    = "S209--19",
  month    =  may,
  year     =  2013,
  address  = "United States",
  keywords = "Brain metastasis; computed tomography; diffusion weighted
              imaging; magnetic resonance imaging; magnetic resonance
              perfusion; magnetic resonance spectroscopy",
  language = "en"
}

@ARTICLE{Pope:2018,
  title    = "Brain metastases: neuroimaging",
  author   = "Pope, Whitney B",
  abstract = "Magnetic resonance imaging (MRI) is the cornerstone for
              evaluating patients with brain masses such as primary and
              metastatic tumors. Important challenges in effectively detecting
              and diagnosing brain metastases and in accurately characterizing
              their subsequent response to treatment remain. These difficulties
              include discriminating metastases from potential mimics such as
              primary brain tumors and infection, detecting small metastases,
              and differentiating treatment response from tumor recurrence and
              progression. Optimal patient management could be benefited by
              improved and well-validated prognostic and predictive imaging
              markers, as well as early response markers to identify successful
              treatment prior to changes in tumor size. To address these
              fundamental needs, newer MRI techniques including diffusion and
              perfusion imaging, MR spectroscopy, and positron emission
              tomography (PET) tracers beyond traditionally used
              18-fluorodeoxyglucose are the subject of extensive ongoing
              investigations, with several promising avenues of added value
              already identified. These newer techniques provide a wealth of
              physiologic and metabolic information that may supplement
              standard MR evaluation, by providing the ability to monitor and
              characterize cellularity, angiogenesis, perfusion, pH, hypoxia,
              metabolite concentrations, and other critical features of
              malignancy. This chapter reviews standard and advanced imaging of
              brain metastases provided by computed tomography, MRI, and amino
              acid PET, focusing on potential biomarkers that can serve as
              problem-solving tools in the clinical management of patients with
              brain metastases.",
  journal  = "Handb Clin Neurol",
  volume   =  149,
  pages    = "89--112",
  year     =  2018,
  address  = "Netherlands",
  keywords = "MRI; PET; amino acid; brain; diffusion; imaging; metastasis;
              perfusion",
  language = "en"
}

@ARTICLE{Pope2018-re,
  title    = "Brain metastases: neuroimaging",
  author   = "Pope, Whitney B",
  abstract = "Magnetic resonance imaging (MRI) is the cornerstone for
              evaluating patients with brain masses such as primary and
              metastatic tumors. Important challenges in effectively detecting
              and diagnosing brain metastases and in accurately characterizing
              their subsequent response to treatment remain. These difficulties
              include discriminating metastases from potential mimics such as
              primary brain tumors and infection, detecting small metastases,
              and differentiating treatment response from tumor recurrence and
              progression. Optimal patient management could be benefited by
              improved and well-validated prognostic and predictive imaging
              markers, as well as early response markers to identify successful
              treatment prior to changes in tumor size. To address these
              fundamental needs, newer MRI techniques including diffusion and
              perfusion imaging, MR spectroscopy, and positron emission
              tomography (PET) tracers beyond traditionally used
              18-fluorodeoxyglucose are the subject of extensive ongoing
              investigations, with several promising avenues of added value
              already identified. These newer techniques provide a wealth of
              physiologic and metabolic information that may supplement
              standard MR evaluation, by providing the ability to monitor and
              characterize cellularity, angiogenesis, perfusion, pH, hypoxia,
              metabolite concentrations, and other critical features of
              malignancy. This chapter reviews standard and advanced imaging of
              brain metastases provided by computed tomography, MRI, and amino
              acid PET, focusing on potential biomarkers that can serve as
              problem-solving tools in the clinical management of patients with
              brain metastases.",
  journal  = "Handb Clin Neurol",
  volume   =  149,
  pages    = "89--112",
  year     =  2018,
  address  = "Netherlands",
  keywords = "MRI; PET; amino acid; brain; diffusion; imaging; metastasis;
              perfusion",
  language = "en"
}

@ARTICLE{Reinke:2021,
       author = {{Reinke}, Annika and {Tizabi}, Minu D. and {Sudre}, Carole H. and {Eisenmann}, Matthias and {R{\"a}dsch}, Tim and {Baumgartner}, Michael and {Acion}, Laura and {Antonelli}, Michela and {Arbel}, Tal and {Bakas}, Spyridon and {Bankhead}, Peter and {Benis}, Arriel and {Cardoso}, M. Jorge and {Cheplygina}, Veronika and {Christodoulou}, Evangelia and {Cimini}, Beth and {Collins}, Gary S. and {Farahani}, Keyvan and {van Ginneken}, Bram and {Glocker}, Ben and {Godau}, Patrick and {Hamprecht}, Fred and {Hashimoto}, Daniel A. and {Heckmann-N{\"o}tzel}, Doreen and {Hoffman}, Michael M. and {Huisman}, Merel and {Isensee}, Fabian and {Jannin}, Pierre and {Kahn}, Charles E. and {Karargyris}, Alexandros and {Karthikesalingam}, Alan and {Kainz}, Bernhard and {Kavur}, Emre and {Kenngott}, Hannes and {Kleesiek}, Jens and {Kooi}, Thijs and {Kozubek}, Michal and {Kreshuk}, Anna and {Kurc}, Tahsin and {Landman}, Bennett A. and {Litjens}, Geert and {Madani}, Amin and {Maier-Hein}, Klaus and {Martel}, Anne L. and {Mattson}, Peter and {Meijering}, Erik and {Menze}, Bjoern and {Moher}, David and {Moons}, Karel G.~M. and {M{\"u}ller}, Henning and {Nichyporuk}, Brennan and {Nickel}, Felix and {Alican Noyan}, M. and {Petersen}, Jens and {Polat}, Gorkem and {Rajpoot}, Nasir and {Reyes}, Mauricio and {Rieke}, Nicola and {Riegler}, Michael and {Rivaz}, Hassan and {Saez-Rodriguez}, Julio and {Sanchez Gutierrez}, Clarisa and {Schroeter}, Julien and {Saha}, Anindo and {Shetty}, Shravya and {van Smeden}, Maarten and {Stieltjes}, Bram and {Summers}, Ronald M. and {Taha}, Abdel A. and {Tsaftaris}, Sotirios A. and {Van Calster}, Ben and {Varoquaux}, Ga{\"e}l and {Wiesenfarth}, Manuel and {Yaniv}, Ziv R. and {Kopp-Schneider}, Annette and {J{\"a}ger}, Paul and {Maier-Hein}, Lena},
        title = "{Common Limitations of Image Processing Metrics: A Picture Story}",
      journal = {arXiv e-prints},
     keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Computer Vision and Pattern Recognition},
         year = 2021,
        month = apr,
          eid = {arXiv:2104.05642},
        pages = {arXiv:2104.05642},
          doi = {10.48550/arXiv.2104.05642},
archivePrefix = {arXiv},
       eprint = {2104.05642},
 primaryClass = {eess.IV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210405642R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Akeret:2021,
  title    = "Topographic volume-standardization atlas of the human brain",
  author   = "Akeret, Kevin and van Niftrik, Christiaan Hendrik Bas and
              Seb{\"o}k, Martina and Muscas, Giovanni and Visser, Thomas and
              Staartjes, Victor E and Marinoni, Federica and Serra, Carlo and
              Regli, Luca and Krayenb{\"u}hl, Niklaus and Piccirelli, Marco and
              Fierstra, Jorn",
  abstract = "Specific anatomical patterns are seen in various diseases
              affecting the brain. Clinical studies on the topography of
              pathologies are often limited by the absence of a normalization
              of the prevalence of pathologies to the relative volume of the
              affected anatomical structures. A comprehensive reference on the
              relative volumes of clinically relevant anatomical structures
              serving for such a normalization, is currently lacking. The
              analyses are based on anatomical high-resolution
              three-dimensional T1-weighted magnetic resonance imaging data of
              30 healthy Caucasian volunteers, including 14 females (mean age
              37.79 years, SD 13.04) and 16 males (mean age 38.31 years, SD
              16.91). Semi-automated anatomical segmentation was used, guided
              by a neuroanatomical parcellation algorithm differentiating 96
              structures. Relative volumes were derived by normalizing
              parenchymal structures to the total individual encephalic volume
              and ventricular segments to the total individual ventricular
              volume. The present investigation provides the absolute and
              relative volumes of 96 anatomical parcellation units of the human
              encephalon. A larger absolute volume in males than in females is
              found for almost all parcellation units. While parenchymal
              structures display a trend towards decreasing volumes with
              increasing age, a significant inverse effect is seen with the
              ventricular system. The variances in volumes as well as the
              effects of gender and age are given for each structure before and
              after normalization. The provided atlas constitutes an
              anatomically detailed and comprehensive analysis of the absolute
              and relative volumes of the human encephalic structures using a
              clinically oriented parcellation algorithm. It is intended to
              serve as a reference for volume-standardization in clinical
              studies on the topographic prevalence of pathologies.",
  journal  = "Brain Struct Funct",
  volume   =  226,
  number   =  6,
  pages    = "1699--1711",
  month    =  may,
  year     =  2021,
  address  = "Germany",
  keywords = "Anatomy; In vivo; Magnetic resonance imaging; Topography; Volumes",
  language = "en"
}
@article{Filipek:1994,
    author = {Filipek, Pauline A. and Richelme, Christian and Kennedy, David N. and Caviness, Verne S., Jr.},
    title = "{The Young Adult Human Brain: An MRI-based Morphometric Analysis}",
    journal = {Cerebral Cortex},
    volume = {4},
    number = {4},
    pages = {344-360},
    year = {1994},
    month = {07},
    abstract = "{Morphometric analysis was performed on three-dimensional MRI scans of 10 male and 10 female young adults with four principal objectives: (1) to characterize in vivo volumes of whole brain and substructures, (2) to explore volumetric symmetry in bilateral structures, (3) to consider the extent to which volumetric measures are dimorphic in the male and female brain, and (4) to provide a normal volumetric database for the young adult brain. Total brain volumes ranged between 1173 and 1626 cm3. All bilateral structures were symmetric or nearly symmetric in volume, with the exception of a slightly larger right neocortex and amygdala, and larger left lateral ventricle. Male brains were larger in volume than female brains, a difference that reached significance for cerebellar but not for cerebral hemisphere volume. In females, there was less cerebral white matter while caudate volume was larger than in the male brains. The proportions of caudate and hippocampus relative to total cerebral volumes were larger in females than in males. These four measures accurately predicted gender in 85\\% of the subjects by discriminant analysis. No gender differences were noted in the structural symmetry analysis. These results represent the first step in establishing a comprehensive database of morphometric parameters, with unexpected findings relative to brain symmetry and sexual dimorphism.}",
    issn = {1047-3211},
    doi = {10.1093/cercor/4.4.344},
    url = {https://doi.org/10.1093/cercor/4.4.344},
    eprint = {https://academic.oup.com/cercor/article-pdf/4/4/344/922104/4-4-344.pdf},
}

@article{Hammers:2003,
author = {Hammers, Alexander and Allom, Richard and Koepp, Matthias J. and Free, Samantha L. and Myers, Ralph and Lemieux, Louis and Mitchell, Tejal N. and Brooks, David J. and Duncan, John S.},
title = {Three-dimensional maximum probability atlas of the human brain, with particular reference to the temporal lobe},
journal = {Human Brain Mapping},
volume = {19},
number = {4},
pages = {224-247},
keywords = {brain mapping, methods, neuroanatomy, atlases, image processing, computer-assisted, anatomy, cross-sectional},
doi = {https://doi.org/10.1002/hbm.10123},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.10123},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.10123},
abstract = {Abstract Probabilistic atlases of neuroanatomy are more representative of population anatomy than single brain atlases. They allow anatomical labeling of the results of group studies in stereotaxic space, automated anatomical labeling of individual brain imaging datasets, and the statistical assessment of normal ranges for structure volumes and extents. No such manually constructed atlas is currently available for the frequently studied group of young adults. We studied 20 normal subjects (10 women, median age 31 years) with high-resolution magnetic resonance imaging (MRI) scanning. Images were nonuniformity corrected and reoriented along both the anterior-posterior commissure (AC–PC) line horizontally and the midsagittal plane sagittally. Building on our previous work, we have expanded and refined existing algorithms for the subdivision of MRI datasets into anatomical structures. The resulting algorithm is presented in the Appendix. Forty-nine structures were interactively defined as three-dimensional volumes-of-interest (VOIs). The resulting 20 individual atlases were spatially transformed (normalized) into standard stereotaxic space, using SPM99 software and the MNI/ICBM 152 template. We evaluated volume data for all structures both in native space and after spatial normalization, and used the normalized superimposed atlases to create a maximum probability map in stereotaxic space, which retains quantitative information regarding inter-subject variability. Its potential applications range from the automatic labeling of new scans to the detection of anatomical abnormalities in patients. Further data can be extracted from the atlas for the detailed analysis of individual structures. Hum. Brain Mapping 19:224–247,2003. ©2003 Wiley-Liss,Inc.},
year = {2003}
}

@ARTICLE{Lancaster:2010,
  title    = "Anatomical Global Spatial Normalization",
  author   = "Lancaster, Jack L and Cykowski, Matthew D and McKay, David Reese
              and Kochunov, Peter V and Fox, Peter T and Rogers, William and
              Toga, Arthur W and Zilles, Karl and Amunts, Katrin and Mazziotta,
              John",
  abstract = "Anatomical global spatial normalization (aGSN) is presented as a
              method to scale high-resolution brain images to control for
              variability in brain size without altering the mean size of other
              brain structures. Two types of mean preserving scaling methods
              were investigated, ``shape preserving'' and ``shape
              standardizing''. aGSN was tested by examining 56 brain structures
              from an adult brain atlas of 40 individuals (LPBA40) before and
              after normalization, with detailed analyses of cerebral
              hemispheres, all gyri collectively, cerebellum, brainstem, and
              left and right caudate, putamen, and hippocampus. Mean sizes of
              brain structures as measured by volume, distance, and area were
              preserved and variance reduced for both types of scale factors.
              An interesting finding was that scale factors derived from each
              of the ten brain structures were also mean preserving. However,
              variance was best reduced using whole brain hemispheres as the
              reference structure, and this reduction was related to its high
              average correlation with other brain structures. The fractional
              reduction in variance of structure volumes was directly related
              to $\rho$2, the square of the reference-to-structure correlation
              coefficient. The average reduction in variance in volumes by aGSN
              with whole brain hemispheres as the reference structure was
              approximately 32\%. An analytical method was provided to directly
              convert between conventional and aGSN scale factors to support
              adaptation of aGSN to popular spatial normalization software
              packages.",
  journal  = "Neuroinformatics",
  volume   =  8,
  number   =  3,
  pages    = "171--182",
  month    =  oct,
  year     =  2010
}

@ARTICLE{Lin:2020,
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Focal Loss for Dense Object Detection}, 
  year={2020},
  volume={42},
  number={2},
  pages={318-327},
  doi={10.1109/TPAMI.2018.2858826}}

@ARTICLE{Sugino:2021,
  title    = "Loss Weightings for Improving Imbalanced Brain Structure
              Segmentation Using Fully Convolutional Networks",
  author   = "Sugino, Takaaki and Kawase, Toshihiro and Onogi, Shinya and Kin,
              Taichi and Saito, Nobuhito and Nakajima, Yoshikazu",
  abstract = "Brain structure segmentation on magnetic resonance (MR) images is
              important for various clinical applications. It has been
              automatically performed by using fully convolutional networks.
              However, it suffers from the class imbalance problem. To address
              this problem, we investigated how loss weighting strategies work
              for brain structure segmentation tasks with different class
              imbalance situations on MR images. In this study, we adopted
              segmentation tasks of the cerebrum, cerebellum, brainstem, and
              blood vessels from MR cisternography and angiography images as
              the target segmentation tasks. We used a U-net architecture with
              cross-entropy and Dice loss functions as a baseline and evaluated
              the effect of the following loss weighting strategies: inverse
              frequency weighting, median inverse frequency weighting, focal
              weighting, distance map-based weighting, and distance penalty
              term-based weighting. In the experiments, the Dice loss function
              with focal weighting showed the best performance and had a high
              average Dice score of 92.8\% in the binary-class segmentation
              tasks, while the cross-entropy loss functions with distance
              map-based weighting achieved the Dice score of up to 93.1\% in
              the multi-class segmentation tasks. The results suggested that
              the distance map-based and the focal weightings could boost the
              performance of cross-entropy and Dice loss functions in class
              imbalanced segmentation tasks, respectively.",
  journal  = "Healthcare (Basel)",
  volume   =  9,
  number   =  8,
  month    =  jul,
  year     =  2021,
  address  = "Switzerland",
  keywords = "brain structure segmentation; class imbalance; fully
              convolutional networks; loss weighting; magnetic resonance images",
  language = "en"
}

@InProceedings{Sudre:2017,
author={Sudre, Carole H.
and Li, Wenqi
and Vercauteren, Tom
and Ourselin, Sebastien
and Jorge Cardoso, M.},
editor={Cardoso, M. Jorge
and Arbel, Tal
and Carneiro, Gustavo
and Syeda-Mahmood, Tanveer
and Tavares, Jo{\~a}o Manuel R.S.
and Moradi, Mehdi
and Bradley, Andrew
and Greenspan, Hayit
and Papa, Jo{\~a}o Paulo
and Madabhushi, Anant
and Nascimento, Jacinto C.
and Cardoso, Jaime S.
and Belagiannis, Vasileios
and Lu, Zhi},
title={Generalised Dice Overlap as a Deep Learning Loss Function for Highly Unbalanced Segmentations},
booktitle={Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
year={2017},
publisher={Springer International Publishing},
address={Cham},
pages={240-248},
abstract={Deep-learning has proved in recent years to be a powerful tool for image analysis and is now widely used to segment both 2D and 3D medical images. Deep-learning segmentation frameworks rely not only on the choice of network architecture but also on the choice of loss function. When the segmentation process targets rare observations, a severe class imbalance is likely to occur between candidate labels, thus resulting in sub-optimal performance. In order to mitigate this issue, strategies such as the weighted cross-entropy function, the sensitivity function or the Dice loss function, have been proposed. In this work, we investigate the behavior of these loss functions and their sensitivity to learning rate tuning in the presence of different rates of label imbalance across 2D and 3D segmentation tasks. We also propose to use the class re-balancing properties of the Generalized Dice overlap, a known metric for segmentation assessment, as a robust and accurate deep-learning loss function for unbalanced tasks.},
isbn={978-3-319-67558-9}
}

@article{Kervadec:2021,
title = {Boundary loss for highly unbalanced segmentation},
journal = {Medical Image Analysis},
volume = {67},
pages = {101851},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2020.101851},
url = {https://www.sciencedirect.com/science/article/pii/S1361841520302152},
author = {Hoel Kervadec and Jihene Bouchtiba and Christian Desrosiers and Eric Granger and Jose Dolz and Ismail {Ben Ayed}},
keywords = {Boundary loss, Unbalanced data, Semantic segmentation, Deep learning, CNN},
abstract = {Widely used loss functions for CNN segmentation, e.g., Dice or cross-entropy, are based on integrals over the segmentation regions. Unfortunately, for highly unbalanced segmentations, such regional summations have values that differ by several orders of magnitude across classes, which affects training performance and stability. We propose a boundary loss, which takes the form of a distance metric on the space of contours, not regions. This can mitigate the difficulties of highly unbalanced problems because it uses integrals over the interface between regions instead of unbalanced integrals over the regions. Furthermore, a boundary loss complements regional information. Inspired by graph-based optimization techniques for computing active-contour flows, we express a non-symmetric L2 distance on the space of contours as a regional integral, which avoids completely local differential computations involving contour points. This yields a boundary loss expressed with the regional softmax probability outputs of the network, which can be easily combined with standard regional losses and implemented with any existing deep network architecture for N-D segmentation. We report comprehensive evaluations and comparisons on different unbalanced problems, showing that our boundary loss can yield significant increases in performances while improving training stability. Our code is publicly available11https://github.com/LIVIAETS/surface-loss.}
}

@ARTICLE{Karimi:2021,
  title    = "Transfer learning in medical image segmentation: New insights
              from analysis of the dynamics of model parameters and learned
              representations",
  author   = "Karimi, Davood and Warfield, Simon K and Gholipour, Ali",
  abstract = "We present a critical assessment of the role of transfer learning
              in training fully convolutional networks (FCNs) for medical image
              segmentation. We first show that although transfer learning
              reduces the training time on the target task, improvements in
              segmentation accuracy are highly task/data-dependent. Large
              improvements are observed only when the segmentation task is more
              challenging and the target training data is smaller. We shed
              light on these observations by investigating the impact of
              transfer learning on the evolution of model parameters and
              learned representations. We observe that convolutional filters
              change little during training and still look random at
              convergence. We further show that quite accurate FCNs can be
              built by freezing the encoder section of the network at random
              values and only training the decoder section. At least for
              medical image segmentation, this finding challenges the common
              belief that the encoder section needs to learn data/task-specific
              representations. We examine the evolution of FCN representations
              to gain a deeper insight into the effects of transfer learning on
              the training dynamics. Our analysis shows that although FCNs
              trained via transfer learning learn different representations
              than FCNs trained with random initialization, the variability
              among FCNs trained via transfer learning can be as high as that
              among FCNs trained with random initialization. Moreover, feature
              reuse is not restricted to the early encoder layers; rather, it
              can be more significant in deeper layers. These findings offer
              new insights and suggest alternative ways of training FCNs for
              medical image segmentation.",
  journal  = "Artif Intell Med",
  volume   =  116,
  pages    = "102078",
  month    =  apr,
  year     =  2021,
  address  = "Netherlands",
  keywords = "Deep learning; Fully convolutional neural networks; Medical image
              segmentation; Transfer learning",
  language = "en"
}

